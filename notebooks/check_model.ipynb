{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check and explore model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "sys.path.insert(0, (Path(\".\").resolve().parent / \"tensorpack-FasterRCNN\").as_posix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from data import get_all_anchors, get_all_anchors_fpn\n",
    "from train import ResNetFPNModel\n",
    "\n",
    "from model_box import (\n",
    "    clip_boxes, decode_bbox_target, encode_bbox_target,\n",
    "    crop_and_resize, roi_align, RPNAnchors)\n",
    "\n",
    "from data import cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNetFPNModel()\n",
    "\n",
    "inputs = model.inputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'image:0' shape=(?, ?, 3) dtype=float32>,\n",
       " <tf.Tensor 'anchor_labels_lvl2:0' shape=(?, ?, 3) dtype=int32>,\n",
       " <tf.Tensor 'anchor_boxes_lvl2:0' shape=(?, ?, 3, 4) dtype=float32>,\n",
       " <tf.Tensor 'anchor_labels_lvl3:0' shape=(?, ?, 3) dtype=int32>,\n",
       " <tf.Tensor 'anchor_boxes_lvl3:0' shape=(?, ?, 3, 4) dtype=float32>,\n",
       " <tf.Tensor 'anchor_labels_lvl4:0' shape=(?, ?, 3) dtype=int32>,\n",
       " <tf.Tensor 'anchor_boxes_lvl4:0' shape=(?, ?, 3, 4) dtype=float32>,\n",
       " <tf.Tensor 'anchor_labels_lvl5:0' shape=(?, ?, 3) dtype=int32>,\n",
       " <tf.Tensor 'anchor_boxes_lvl5:0' shape=(?, ?, 3, 4) dtype=float32>,\n",
       " <tf.Tensor 'anchor_labels_lvl6:0' shape=(?, ?, 3) dtype=int32>,\n",
       " <tf.Tensor 'anchor_boxes_lvl6:0' shape=(?, ?, 3, 4) dtype=float32>,\n",
       " <tf.Tensor 'gt_boxes:0' shape=(?, 4) dtype=float32>,\n",
       " <tf.Tensor 'gt_labels:0' shape=(?,) dtype=int64>,\n",
       " <tf.Tensor 'gt_masks:0' shape=(?, ?, ?) dtype=uint8>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_fpn_level = len(cfg.FPN.ANCHOR_STRIDES)\n",
    "assert len(cfg.RPN.ANCHOR_SIZES) == num_fpn_level\n",
    "\n",
    "image = inputs[0]\n",
    "input_anchors = inputs[1: 1 + 2 * num_fpn_level]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 5\n",
      "Level 2 | shape (334, 334, 3, 4)\n",
      "Level 3 | shape (167, 167, 3, 4)\n",
      "Level 4 | shape (84, 84, 3, 4)\n",
      "Level 5 | shape (42, 42, 3, 4)\n",
      "Level 6 | shape (21, 21, 3, 4)\n"
     ]
    }
   ],
   "source": [
    "all_anchors_fpn = get_all_anchors_fpn()\n",
    "print(type(all_anchors_fpn), len(all_anchors_fpn))\n",
    "for i, single_level_anchors in enumerate(all_anchors_fpn):\n",
    "    print(\"Level {} | shape {}\".format(i + 2, single_level_anchors.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "multilevel_anchors = [RPNAnchors(*args) for args in\n",
    "                      zip(get_all_anchors_fpn(), input_anchors[0::2], input_anchors[1::2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(multilevel_anchors), len(multilevel_anchors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level 2 | <class 'model_box.RPNAnchors'>\n",
      "Level 3 | <class 'model_box.RPNAnchors'>\n",
      "Level 4 | <class 'model_box.RPNAnchors'>\n",
      "Level 5 | <class 'model_box.RPNAnchors'>\n",
      "Level 6 | <class 'model_box.RPNAnchors'>\n"
     ]
    }
   ],
   "source": [
    "for i, rpn_anchors in enumerate(multilevel_anchors):\n",
    "    print(\"Level {} | {}\".format(i + 2, type(rpn_anchors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_boxes, gt_labels = inputs[11], inputs[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = model.preprocess(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from basemodel import (\n",
    "    image_preprocess, resnet_c4_backbone, resnet_conv5,\n",
    "    resnet_fpn_backbone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0708 21:56:43 @config.py:191]\u001b[0m Config: ------------------------------------------\n",
      "{'BACKBONE': {'FREEZE_AFFINE': False,\n",
      "              'NORM': 'FreezeBN',\n",
      "              'RESNET_NUM_BLOCK': [3, 4, 6, 3],\n",
      "              'STRIDE_1X1': False,\n",
      "              'TF_PAD_MODE': True,\n",
      "              'WEIGHTS': ''},\n",
      " 'DATA': {'BASEDIR': '.',\n",
      "          'CLASS_NAMES': [],\n",
      "          'NUM_CATEGORY': 601,\n",
      "          'NUM_CLASS': 602,\n",
      "          'TRAIN': ['test', 'val_0.7'],\n",
      "          'VAL': 'val_0.3'},\n",
      " 'FPN': {'ANCHOR_STRIDES': (4, 8, 16, 32, 64),\n",
      "         'FRCNN_CONV_HEAD_DIM': 256,\n",
      "         'FRCNN_FC_HEAD_DIM': 1024,\n",
      "         'FRCNN_HEAD_FUNC': 'fastrcnn_2fc_head',\n",
      "         'NUM_CHANNEL': 256,\n",
      "         'RESOLUTION_REQUIREMENT': 32},\n",
      " 'FRCNN': {'BATCH_PER_IM': 512,\n",
      "           'BBOX_REG_WEIGHTS': [10.0, 10.0, 5.0, 5.0],\n",
      "           'FG_RATIO': 0.25,\n",
      "           'FG_THRESH': 0.5},\n",
      " 'MODE_FPN': False,\n",
      " 'MODE_MASK': True,\n",
      " 'MRCNN': {'HEAD_DIM': 256},\n",
      " 'PREPROC': {'MAX_SIZE': 1333,\n",
      "             'PIXEL_MEAN': [123.675, 116.28, 103.53],\n",
      "             'PIXEL_STD': [58.395, 57.12, 57.375],\n",
      "             'SHORT_EDGE_SIZE': 800},\n",
      " 'RPN': {'ANCHOR_RATIOS': (0.5, 1.0, 2.0),\n",
      "         'ANCHOR_SIZES': (32, 64, 128, 256, 512),\n",
      "         'ANCHOR_STRIDE': 16,\n",
      "         'BATCH_PER_IM': 256,\n",
      "         'CROWD_OVERLAP_THRES': 0.7,\n",
      "         'FG_RATIO': 0.5,\n",
      "         'HEAD_DIM': 1024,\n",
      "         'MIN_SIZE': 0,\n",
      "         'NEGATIVE_ANCHOR_THRES': 0.3,\n",
      "         'NUM_ANCHOR': 15,\n",
      "         'POSITIVE_ANCHOR_THRES': 0.7,\n",
      "         'PROPOSAL_NMS_THRESH': 0.7,\n",
      "         'TEST_FPN_NMS_TOPK': 1000,\n",
      "         'TEST_POST_NMS_TOPK': 1000,\n",
      "         'TEST_PRE_NMS_TOPK': 6000,\n",
      "         'TRAIN_FPN_NMS_TOPK': 2000,\n",
      "         'TRAIN_POST_NMS_TOPK': 2000,\n",
      "         'TRAIN_PRE_NMS_TOPK': 12000},\n",
      " 'TEST': {'FRCNN_NMS_THRESH': 0.5,\n",
      "          'RESULTS_PER_IM': 100,\n",
      "          'RESULT_SCORE_THRESH': 0.05,\n",
      "          'RESULT_SCORE_THRESH_VIS': 0.3},\n",
      " 'TRAIN': {'BASE_LR': 0.01,\n",
      "           'EVAL_INTERVAL_EPOCH': 30,\n",
      "           'GAMMA': 0.1,\n",
      "           'LR_SCHEDULE': [240000, 320000, 360000],\n",
      "           'NUM_GPUS': 1,\n",
      "           'STEPS_PER_EPOCH': 500,\n",
      "           'WARMUP': 1000,\n",
      "           'WEIGHT_DECAY': 0.0001},\n",
      " 'TRAINER': 'replicated'}\n"
     ]
    }
   ],
   "source": [
    "from config import finalize_configs\n",
    "\n",
    "finalize_configs(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0708 21:56:43 @registry.py:121]\u001b[0m conv0 input: [1, 3, None, None]\n",
      "\u001b[32m[0708 21:56:43 @batch_norm.py:164]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0708 21:56:43 @registry.py:129]\u001b[0m conv0 output: [1, 64, None, None]\n",
      "\u001b[32m[0708 21:56:43 @registry.py:121]\u001b[0m pool0 input: [1, 64, None, None]\n",
      "\u001b[32m[0708 21:56:43 @registry.py:129]\u001b[0m pool0 output: [1, 64, None, None]\n",
      "\u001b[32m[0708 21:56:43 @registry.py:121]\u001b[0m group0/block0/conv1 input: [1, 64, None, None]\n",
      "\u001b[32m[0708 21:56:43 @batch_norm.py:164]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0708 21:56:43 @registry.py:129]\u001b[0m group0/block0/conv1 output: [1, 64, None, None]\n",
      "\u001b[32m[0708 21:56:43 @registry.py:121]\u001b[0m group0/block0/conv2 input: [1, 64, None, None]\n",
      "\u001b[32m[0708 21:56:43 @batch_norm.py:164]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0708 21:56:43 @registry.py:129]\u001b[0m group0/block0/conv2 output: [1, 64, None, None]\n",
      "\u001b[32m[0708 21:56:43 @registry.py:121]\u001b[0m group0/block0/conv3 input: [1, 64, None, None]\n",
      "\u001b[32m[0708 21:56:43 @batch_norm.py:164]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0708 21:56:43 @registry.py:129]\u001b[0m group0/block0/conv3 output: [1, 256, None, None]\n",
      "\u001b[32m[0708 21:56:43 @registry.py:121]\u001b[0m group0/block0/convshortcut input: [1, 64, None, None]\n",
      "\u001b[32m[0708 21:56:43 @batch_norm.py:164]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0708 21:56:43 @registry.py:129]\u001b[0m group0/block0/convshortcut output: [1, 256, None, None]\n",
      "\u001b[32m[0708 21:56:43 @registry.py:121]\u001b[0m group0/block1/conv1 input: [1, 256, None, None]\n",
      "\u001b[32m[0708 21:56:43 @batch_norm.py:164]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0708 21:56:43 @registry.py:129]\u001b[0m group0/block1/conv1 output: [1, 64, None, None]\n",
      "\u001b[32m[0708 21:56:43 @registry.py:121]\u001b[0m group0/block1/conv2 input: [1, 64, None, None]\n",
      "\u001b[32m[0708 21:56:43 @batch_norm.py:164]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0708 21:56:43 @registry.py:129]\u001b[0m group0/block1/conv2 output: [1, 64, None, None]\n",
      "\u001b[32m[0708 21:56:43 @registry.py:121]\u001b[0m group0/block1/conv3 input: [1, 64, None, None]\n",
      "\u001b[32m[0708 21:56:43 @batch_norm.py:164]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0708 21:56:43 @registry.py:129]\u001b[0m group0/block1/conv3 output: [1, 256, None, None]\n",
      "\u001b[32m[0708 21:56:43 @registry.py:121]\u001b[0m group0/block2/conv1 input: [1, 256, None, None]\n",
      "\u001b[32m[0708 21:56:43 @batch_norm.py:164]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0708 21:56:43 @registry.py:129]\u001b[0m group0/block2/conv1 output: [1, 64, None, None]\n",
      "\u001b[32m[0708 21:56:43 @registry.py:121]\u001b[0m group0/block2/conv2 input: [1, 64, None, None]\n",
      "\u001b[32m[0708 21:56:43 @batch_norm.py:164]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0708 21:56:43 @registry.py:129]\u001b[0m group0/block2/conv2 output: [1, 64, None, None]\n",
      "\u001b[32m[0708 21:56:43 @registry.py:121]\u001b[0m group0/block2/conv3 input: [1, 64, None, None]\n",
      "\u001b[32m[0708 21:56:43 @batch_norm.py:164]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0708 21:56:43 @registry.py:129]\u001b[0m group0/block2/conv3 output: [1, 256, None, None]\n",
      "\u001b[32m[0708 21:56:43 @registry.py:121]\u001b[0m group1/block0/conv1 input: [1, 256, None, None]\n",
      "\u001b[32m[0708 21:56:43 @batch_norm.py:164]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0708 21:56:43 @registry.py:129]\u001b[0m group1/block0/conv1 output: [1, 128, None, None]\n",
      "\u001b[32m[0708 21:56:43 @registry.py:121]\u001b[0m group1/block0/conv2 input: [1, 128, None, None]\n",
      "\u001b[32m[0708 21:56:43 @batch_norm.py:164]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0708 21:56:43 @registry.py:129]\u001b[0m group1/block0/conv2 output: [1, 128, None, None]\n",
      "\u001b[32m[0708 21:56:43 @registry.py:121]\u001b[0m group1/block0/conv3 input: [1, 128, None, None]\n",
      "\u001b[32m[0708 21:56:43 @batch_norm.py:164]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0708 21:56:43 @registry.py:129]\u001b[0m group1/block0/conv3 output: [1, 512, None, None]\n",
      "\u001b[32m[0708 21:56:43 @registry.py:121]\u001b[0m group1/block0/convshortcut input: [1, 256, None, None]\n",
      "\u001b[32m[0708 21:56:43 @batch_norm.py:164]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0708 21:56:43 @registry.py:129]\u001b[0m group1/block0/convshortcut output: [1, 512, None, None]\n",
      "\u001b[32m[0708 21:56:43 @registry.py:121]\u001b[0m group1/block1/conv1 input: [1, 512, None, None]\n",
      "\u001b[32m[0708 21:56:43 @batch_norm.py:164]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0708 21:56:43 @registry.py:129]\u001b[0m group1/block1/conv1 output: [1, 128, None, None]\n",
      "\u001b[32m[0708 21:56:43 @registry.py:121]\u001b[0m group1/block1/conv2 input: [1, 128, None, None]\n",
      "\u001b[32m[0708 21:56:43 @batch_norm.py:164]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0708 21:56:43 @registry.py:129]\u001b[0m group1/block1/conv2 output: [1, 128, None, None]\n",
      "\u001b[32m[0708 21:56:43 @registry.py:121]\u001b[0m group1/block1/conv3 input: [1, 128, None, None]\n",
      "\u001b[32m[0708 21:56:43 @batch_norm.py:164]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0708 21:56:43 @registry.py:129]\u001b[0m group1/block1/conv3 output: [1, 512, None, None]\n",
      "\u001b[32m[0708 21:56:43 @registry.py:121]\u001b[0m group1/block2/conv1 input: [1, 512, None, None]\n",
      "\u001b[32m[0708 21:56:43 @batch_norm.py:164]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0708 21:56:43 @registry.py:129]\u001b[0m group1/block2/conv1 output: [1, 128, None, None]\n",
      "\u001b[32m[0708 21:56:43 @registry.py:121]\u001b[0m group1/block2/conv2 input: [1, 128, None, None]\n",
      "\u001b[32m[0708 21:56:43 @batch_norm.py:164]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0708 21:56:43 @registry.py:129]\u001b[0m group1/block2/conv2 output: [1, 128, None, None]\n",
      "\u001b[32m[0708 21:56:43 @registry.py:121]\u001b[0m group1/block2/conv3 input: [1, 128, None, None]\n",
      "\u001b[32m[0708 21:56:43 @batch_norm.py:164]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0708 21:56:43 @registry.py:129]\u001b[0m group1/block2/conv3 output: [1, 512, None, None]\n",
      "\u001b[32m[0708 21:56:43 @registry.py:121]\u001b[0m group1/block3/conv1 input: [1, 512, None, None]\n",
      "\u001b[32m[0708 21:56:43 @batch_norm.py:164]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0708 21:56:43 @registry.py:129]\u001b[0m group1/block3/conv1 output: [1, 128, None, None]\n",
      "\u001b[32m[0708 21:56:43 @registry.py:121]\u001b[0m group1/block3/conv2 input: [1, 128, None, None]\n",
      "\u001b[32m[0708 21:56:43 @batch_norm.py:164]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0708 21:56:44 @registry.py:129]\u001b[0m group1/block3/conv2 output: [1, 128, None, None]\n",
      "\u001b[32m[0708 21:56:44 @registry.py:121]\u001b[0m group1/block3/conv3 input: [1, 128, None, None]\n",
      "\u001b[32m[0708 21:56:44 @batch_norm.py:164]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0708 21:56:44 @registry.py:129]\u001b[0m group1/block3/conv3 output: [1, 512, None, None]\n",
      "\u001b[32m[0708 21:56:44 @registry.py:121]\u001b[0m group2/block0/conv1 input: [1, 512, None, None]\n",
      "\u001b[32m[0708 21:56:44 @batch_norm.py:164]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0708 21:56:44 @registry.py:129]\u001b[0m group2/block0/conv1 output: [1, 256, None, None]\n",
      "\u001b[32m[0708 21:56:44 @registry.py:121]\u001b[0m group2/block0/conv2 input: [1, 256, None, None]\n",
      "\u001b[32m[0708 21:56:44 @batch_norm.py:164]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0708 21:56:44 @registry.py:129]\u001b[0m group2/block0/conv2 output: [1, 256, None, None]\n",
      "\u001b[32m[0708 21:56:44 @registry.py:121]\u001b[0m group2/block0/conv3 input: [1, 256, None, None]\n",
      "\u001b[32m[0708 21:56:44 @batch_norm.py:164]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0708 21:56:44 @registry.py:129]\u001b[0m group2/block0/conv3 output: [1, 1024, None, None]\n",
      "\u001b[32m[0708 21:56:44 @registry.py:121]\u001b[0m group2/block0/convshortcut input: [1, 512, None, None]\n",
      "\u001b[32m[0708 21:56:44 @batch_norm.py:164]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0708 21:56:44 @registry.py:129]\u001b[0m group2/block0/convshortcut output: [1, 1024, None, None]\n",
      "\u001b[32m[0708 21:56:44 @registry.py:121]\u001b[0m group2/block1/conv1 input: [1, 1024, None, None]\n",
      "\u001b[32m[0708 21:56:44 @batch_norm.py:164]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0708 21:56:44 @registry.py:129]\u001b[0m group2/block1/conv1 output: [1, 256, None, None]\n",
      "\u001b[32m[0708 21:56:44 @registry.py:121]\u001b[0m group2/block1/conv2 input: [1, 256, None, None]\n",
      "\u001b[32m[0708 21:56:44 @batch_norm.py:164]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0708 21:56:44 @registry.py:129]\u001b[0m group2/block1/conv2 output: [1, 256, None, None]\n",
      "\u001b[32m[0708 21:56:44 @registry.py:121]\u001b[0m group2/block1/conv3 input: [1, 256, None, None]\n",
      "\u001b[32m[0708 21:56:44 @batch_norm.py:164]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0708 21:56:44 @registry.py:129]\u001b[0m group2/block1/conv3 output: [1, 1024, None, None]\n",
      "\u001b[32m[0708 21:56:44 @registry.py:121]\u001b[0m group2/block2/conv1 input: [1, 1024, None, None]\n",
      "\u001b[32m[0708 21:56:44 @batch_norm.py:164]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0708 21:56:44 @registry.py:129]\u001b[0m group2/block2/conv1 output: [1, 256, None, None]\n",
      "\u001b[32m[0708 21:56:44 @registry.py:121]\u001b[0m group2/block2/conv2 input: [1, 256, None, None]\n",
      "\u001b[32m[0708 21:56:44 @batch_norm.py:164]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0708 21:56:44 @registry.py:129]\u001b[0m group2/block2/conv2 output: [1, 256, None, None]\n",
      "\u001b[32m[0708 21:56:44 @registry.py:121]\u001b[0m group2/block2/conv3 input: [1, 256, None, None]\n",
      "\u001b[32m[0708 21:56:44 @batch_norm.py:164]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0708 21:56:44 @registry.py:129]\u001b[0m group2/block2/conv3 output: [1, 1024, None, None]\n",
      "\u001b[32m[0708 21:56:44 @registry.py:121]\u001b[0m group2/block3/conv1 input: [1, 1024, None, None]\n",
      "\u001b[32m[0708 21:56:44 @batch_norm.py:164]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0708 21:56:44 @registry.py:129]\u001b[0m group2/block3/conv1 output: [1, 256, None, None]\n",
      "\u001b[32m[0708 21:56:44 @registry.py:121]\u001b[0m group2/block3/conv2 input: [1, 256, None, None]\n",
      "\u001b[32m[0708 21:56:44 @batch_norm.py:164]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0708 21:56:44 @registry.py:129]\u001b[0m group2/block3/conv2 output: [1, 256, None, None]\n",
      "\u001b[32m[0708 21:56:44 @registry.py:121]\u001b[0m group2/block3/conv3 input: [1, 256, None, None]\n",
      "\u001b[32m[0708 21:56:44 @batch_norm.py:164]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0708 21:56:44 @registry.py:129]\u001b[0m group2/block3/conv3 output: [1, 1024, None, None]\n",
      "\u001b[32m[0708 21:56:44 @registry.py:121]\u001b[0m group2/block4/conv1 input: [1, 1024, None, None]\n",
      "\u001b[32m[0708 21:56:44 @batch_norm.py:164]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0708 21:56:44 @registry.py:129]\u001b[0m group2/block4/conv1 output: [1, 256, None, None]\n",
      "\u001b[32m[0708 21:56:44 @registry.py:121]\u001b[0m group2/block4/conv2 input: [1, 256, None, None]\n",
      "\u001b[32m[0708 21:56:44 @batch_norm.py:164]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0708 21:56:44 @registry.py:129]\u001b[0m group2/block4/conv2 output: [1, 256, None, None]\n",
      "\u001b[32m[0708 21:56:44 @registry.py:121]\u001b[0m group2/block4/conv3 input: [1, 256, None, None]\n",
      "\u001b[32m[0708 21:56:44 @batch_norm.py:164]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0708 21:56:44 @registry.py:129]\u001b[0m group2/block4/conv3 output: [1, 1024, None, None]\n",
      "\u001b[32m[0708 21:56:44 @registry.py:121]\u001b[0m group2/block5/conv1 input: [1, 1024, None, None]\n",
      "\u001b[32m[0708 21:56:44 @batch_norm.py:164]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0708 21:56:44 @registry.py:129]\u001b[0m group2/block5/conv1 output: [1, 256, None, None]\n",
      "\u001b[32m[0708 21:56:44 @registry.py:121]\u001b[0m group2/block5/conv2 input: [1, 256, None, None]\n",
      "\u001b[32m[0708 21:56:44 @batch_norm.py:164]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0708 21:56:44 @registry.py:129]\u001b[0m group2/block5/conv2 output: [1, 256, None, None]\n",
      "\u001b[32m[0708 21:56:44 @registry.py:121]\u001b[0m group2/block5/conv3 input: [1, 256, None, None]\n",
      "\u001b[32m[0708 21:56:44 @batch_norm.py:164]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0708 21:56:44 @registry.py:129]\u001b[0m group2/block5/conv3 output: [1, 1024, None, None]\n",
      "\u001b[32m[0708 21:56:44 @registry.py:121]\u001b[0m group3/block0/conv1 input: [1, 1024, None, None]\n",
      "\u001b[32m[0708 21:56:44 @batch_norm.py:164]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0708 21:56:44 @registry.py:129]\u001b[0m group3/block0/conv1 output: [1, 512, None, None]\n",
      "\u001b[32m[0708 21:56:44 @registry.py:121]\u001b[0m group3/block0/conv2 input: [1, 512, None, None]\n",
      "\u001b[32m[0708 21:56:44 @batch_norm.py:164]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0708 21:56:44 @registry.py:129]\u001b[0m group3/block0/conv2 output: [1, 512, None, None]\n",
      "\u001b[32m[0708 21:56:44 @registry.py:121]\u001b[0m group3/block0/conv3 input: [1, 512, None, None]\n",
      "\u001b[32m[0708 21:56:44 @batch_norm.py:164]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0708 21:56:44 @registry.py:129]\u001b[0m group3/block0/conv3 output: [1, 2048, None, None]\n",
      "\u001b[32m[0708 21:56:44 @registry.py:121]\u001b[0m group3/block0/convshortcut input: [1, 1024, None, None]\n",
      "\u001b[32m[0708 21:56:44 @batch_norm.py:164]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0708 21:56:44 @registry.py:129]\u001b[0m group3/block0/convshortcut output: [1, 2048, None, None]\n",
      "\u001b[32m[0708 21:56:44 @registry.py:121]\u001b[0m group3/block1/conv1 input: [1, 2048, None, None]\n",
      "\u001b[32m[0708 21:56:44 @batch_norm.py:164]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0708 21:56:44 @registry.py:129]\u001b[0m group3/block1/conv1 output: [1, 512, None, None]\n",
      "\u001b[32m[0708 21:56:44 @registry.py:121]\u001b[0m group3/block1/conv2 input: [1, 512, None, None]\n",
      "\u001b[32m[0708 21:56:44 @batch_norm.py:164]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0708 21:56:44 @registry.py:129]\u001b[0m group3/block1/conv2 output: [1, 512, None, None]\n",
      "\u001b[32m[0708 21:56:44 @registry.py:121]\u001b[0m group3/block1/conv3 input: [1, 512, None, None]\n",
      "\u001b[32m[0708 21:56:44 @batch_norm.py:164]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0708 21:56:44 @registry.py:129]\u001b[0m group3/block1/conv3 output: [1, 2048, None, None]\n",
      "\u001b[32m[0708 21:56:44 @registry.py:121]\u001b[0m group3/block2/conv1 input: [1, 2048, None, None]\n",
      "\u001b[32m[0708 21:56:45 @batch_norm.py:164]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0708 21:56:45 @registry.py:129]\u001b[0m group3/block2/conv1 output: [1, 512, None, None]\n",
      "\u001b[32m[0708 21:56:45 @registry.py:121]\u001b[0m group3/block2/conv2 input: [1, 512, None, None]\n",
      "\u001b[32m[0708 21:56:45 @batch_norm.py:164]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0708 21:56:45 @registry.py:129]\u001b[0m group3/block2/conv2 output: [1, 512, None, None]\n",
      "\u001b[32m[0708 21:56:45 @registry.py:121]\u001b[0m group3/block2/conv3 input: [1, 512, None, None]\n",
      "\u001b[32m[0708 21:56:45 @batch_norm.py:164]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0708 21:56:45 @registry.py:129]\u001b[0m group3/block2/conv3 output: [1, 2048, None, None]\n"
     ]
    }
   ],
   "source": [
    "from tensorpack.tfutils.tower import TowerContext\n",
    "\n",
    "with TowerContext('tower0', is_training=True):\n",
    "    c2345 = resnet_fpn_backbone(image, cfg.BACKBONE.RESNET_NUM_BLOCK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'tower0/StopGradient:0' shape=(1, 256, ?, ?) dtype=float32>,\n",
       " <tf.Tensor 'tower0/group1/block3/output:0' shape=(1, 512, ?, ?) dtype=float32>,\n",
       " <tf.Tensor 'tower0/group2/block5/output:0' shape=(1, 1024, ?, ?) dtype=float32>,\n",
       " <tf.Tensor 'tower0/group3/block2/output:0' shape=(1, 2048, ?, ?) dtype=float32>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_fpn import (\n",
    "    fpn_model, multilevel_roi_align,\n",
    "    multilevel_rpn_losses, generate_fpn_proposals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mfpn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "\u001b[0;34m@\u001b[0m\u001b[0mlayer_register\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;32mdef\u001b[0m \u001b[0mfpn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"\u001b[0m\n",
       "\u001b[0;34m    Args:\u001b[0m\n",
       "\u001b[0;34m        features ([tf.Tensor]): ResNet features c2-c5\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Returns:\u001b[0m\n",
       "\u001b[0;34m        [tf.Tensor]: FPN features p2-p6\u001b[0m\n",
       "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnum_channel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFPN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNUM_CHANNEL\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mupsample2x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mFixedUnPooling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munpool_mat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'channels_first'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# tf.image.resize is, again, not aligned.\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# with tf.name_scope(name):\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m#     shape2d = tf.shape(x)[2:]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m#     x = tf.transpose(x, [0, 2, 3, 1])\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m#     x = tf.image.resize_nearest_neighbor(x, shape2d * 2, align_corners=True)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m#     x = tf.transpose(x, [0, 3, 1, 2])\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m#     return x\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mwith\u001b[0m \u001b[0margscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'channels_first'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                  \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_bias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                  \u001b[0mkernel_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariance_scaling_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mlat_2345\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lateral_1x1_c{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_channel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mlat_sum_5432\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlat_2345\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mlat_sum_5432\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mlat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlat\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mupsample2x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'upsample_lat{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlat_sum_5432\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mlat_sum_5432\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mp2345\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'posthoc_3x3_p{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_channel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlat_sum_5432\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mp6\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMaxPooling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'maxpool_p6'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp2345\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'channels_first'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mp2345\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      /home/working_directory/ml/kaggle/OpenImagesObjectDetection/tensorpack-FasterRCNN/model_fpn.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpn_model??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "features = [\n",
    "    tf.placeholder(tf.float32, shape=(1, 256, None, None), name='c2'),\n",
    "    tf.placeholder(tf.float32, shape=(1, 512, None, None), name='c3'),\n",
    "    tf.placeholder(tf.float32, shape=(1, 1024, None, None), name='c4'),\n",
    "    tf.placeholder(tf.float32, shape=(1, 2048, None, None), name='c5'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-8154164f72da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mp23456\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfpn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorpack/models/registry.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0muse_scope\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m                 \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# actual positional args used to call func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                 assert isinstance(name, six.string_types), \"First argument for \\\"{}\\\" should be a string. \".format(\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "p23456 = fpn_model(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
