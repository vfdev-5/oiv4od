{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check dataflow:\n",
    "- training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "sys.path.insert(0, (Path(\".\").resolve().parent / \"tensorpack-FasterRCNN\").as_posix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from data import get_train_dataflow, cfg, COCODetection, logger, DataFromList, CustomResize, imgaug, cv2\n",
    "from data import box_to_point8, point8_to_box, get_multilevel_rpn_anchor_input, itertools, copy\n",
    "from data import np_area, np_iou, MalformedData, get_rpn_anchor_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.DATA.BASEDIR=\"../input/as_mscoco\"\n",
    "cfg.MODE_MASK = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import finalize_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0708 08:45:45 @config.py:190]\u001b[0m Config: ------------------------------------------\n",
      "{'BACKBONE': {'FREEZE_AFFINE': False,\n",
      "              'NORM': 'FreezeBN',\n",
      "              'RESNET_NUM_BLOCK': [3, 4, 6, 3],\n",
      "              'STRIDE_1X1': False,\n",
      "              'TF_PAD_MODE': True,\n",
      "              'WEIGHTS': ''},\n",
      " 'DATA': {'BASEDIR': '../input/as_mscoco',\n",
      "          'CLASS_NAMES': [],\n",
      "          'NUM_CATEGORY': 601,\n",
      "          'NUM_CLASS': 602,\n",
      "          'TRAIN': ['test'],\n",
      "          'VAL': 'val'},\n",
      " 'FPN': {'ANCHOR_STRIDES': (4, 8, 16, 32, 64),\n",
      "         'FRCNN_CONV_HEAD_DIM': 256,\n",
      "         'FRCNN_FC_HEAD_DIM': 1024,\n",
      "         'FRCNN_HEAD_FUNC': 'fastrcnn_2fc_head',\n",
      "         'NUM_CHANNEL': 256,\n",
      "         'RESOLUTION_REQUIREMENT': 32},\n",
      " 'FRCNN': {'BATCH_PER_IM': 512,\n",
      "           'BBOX_REG_WEIGHTS': [10.0, 10.0, 5.0, 5.0],\n",
      "           'FG_RATIO': 0.25,\n",
      "           'FG_THRESH': 0.5},\n",
      " 'MODE_FPN': False,\n",
      " 'MODE_MASK': False,\n",
      " 'MRCNN': {'HEAD_DIM': 256},\n",
      " 'PREPROC': {'MAX_SIZE': 1333,\n",
      "             'PIXEL_MEAN': [123.675, 116.28, 103.53],\n",
      "             'PIXEL_STD': [58.395, 57.12, 57.375],\n",
      "             'SHORT_EDGE_SIZE': 800},\n",
      " 'RPN': {'ANCHOR_RATIOS': (0.5, 1.0, 2.0),\n",
      "         'ANCHOR_SIZES': (32, 64, 128, 256, 512),\n",
      "         'ANCHOR_STRIDE': 16,\n",
      "         'BATCH_PER_IM': 256,\n",
      "         'CROWD_OVERLAP_THRES': 0.7,\n",
      "         'FG_RATIO': 0.5,\n",
      "         'HEAD_DIM': 1024,\n",
      "         'MIN_SIZE': 0,\n",
      "         'NEGATIVE_ANCHOR_THRES': 0.3,\n",
      "         'NUM_ANCHOR': 15,\n",
      "         'POSITIVE_ANCHOR_THRES': 0.7,\n",
      "         'PROPOSAL_NMS_THRESH': 0.7,\n",
      "         'TEST_FPN_NMS_TOPK': 1000,\n",
      "         'TEST_POST_NMS_TOPK': 1000,\n",
      "         'TEST_PRE_NMS_TOPK': 6000,\n",
      "         'TRAIN_FPN_NMS_TOPK': 2000,\n",
      "         'TRAIN_POST_NMS_TOPK': 2000,\n",
      "         'TRAIN_PRE_NMS_TOPK': 12000},\n",
      " 'TEST': {'FRCNN_NMS_THRESH': 0.5,\n",
      "          'RESULTS_PER_IM': 100,\n",
      "          'RESULT_SCORE_THRESH': 0.05,\n",
      "          'RESULT_SCORE_THRESH_VIS': 0.3},\n",
      " 'TRAIN': {'BASE_LR': 0.01,\n",
      "           'EVAL_INTERVAL_EPOCH': 30,\n",
      "           'LR_SCHEDULE': [240000, 320000, 360000],\n",
      "           'NUM_GPUS': 1,\n",
      "           'STEPS_PER_EPOCH': 500,\n",
      "           'WARMUP': 1000,\n",
      "           'WEIGHT_DECAY': 0.0001},\n",
      " 'TRAINER': 'replicated'}\n"
     ]
    }
   ],
   "source": [
    "_ = finalize_configs(is_training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=5.17s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[0707 14:53:19 @coco.py:76]\u001b[0m Instances loaded from ../input/as_mscoco/annotations/test.json.\n",
      "\u001b[32m[0707 14:53:37 @timer.py:44]\u001b[0m Load Groundtruth Boxes for test finished, time:17.4501sec.\n",
      "\u001b[32m[0707 14:53:38 @<ipython-input-11-890d433247b5>:5]\u001b[0m Filtered 0 images which contain no groudtruth boxes. Total #images for training: 107988\n"
     ]
    }
   ],
   "source": [
    "imgs = COCODetection.load_many(cfg.DATA.BASEDIR, cfg.DATA.TRAIN, add_gt=True, add_mask=cfg.MODE_MASK)\n",
    "num = len(imgs)\n",
    "imgs = list(filter(lambda img: len(img['boxes']) > 0, imgs))    # log invalid training\n",
    "logger.info(\"Filtered {} images which contain no groudtruth boxes. Total #images for training: {}\"\n",
    "            .format(num - len(imgs), len(imgs)))\n",
    "\n",
    "ds = DataFromList(imgs, shuffle=True)\n",
    "\n",
    "aug = imgaug.AugmentorList(\n",
    "    [CustomResize(cfg.PREPROC.SHORT_EDGE_SIZE, cfg.PREPROC.MAX_SIZE),\n",
    "     imgaug.Flip(horiz=True)])\n",
    "\n",
    "def preprocess(img):\n",
    "    fname, boxes, klass, is_crowd = img['file_name'], img['boxes'], img['class'], img['is_crowd']\n",
    "    boxes = np.copy(boxes)\n",
    "    im = cv2.imread(fname, cv2.IMREAD_COLOR)\n",
    "    assert im is not None, fname\n",
    "    im = im.astype('float32')\n",
    "    # assume floatbox as input\n",
    "    assert boxes.dtype == np.float32, \"Loader has to return floating point boxes!\"\n",
    "\n",
    "    # augmentation:\n",
    "    im, params = aug.augment_return_params(im)\n",
    "    points = box_to_point8(boxes)\n",
    "    points = aug.augment_coords(points, params)\n",
    "    boxes = point8_to_box(points)\n",
    "    assert np.min(np_area(boxes)) > 0, \"Some boxes have zero area!\"\n",
    "\n",
    "    # rpn anchor:\n",
    "    try:\n",
    "        if cfg.MODE_FPN:\n",
    "            multilevel_anchor_inputs = get_multilevel_rpn_anchor_input(im, boxes, is_crowd)\n",
    "            anchor_inputs = itertools.chain.from_iterable(multilevel_anchor_inputs)\n",
    "        else:\n",
    "            # anchor_labels, anchor_boxes\n",
    "            anchor_inputs = get_rpn_anchor_input(im, boxes, is_crowd)\n",
    "            assert len(anchor_inputs) == 2\n",
    "\n",
    "        boxes = boxes[is_crowd == 0]    # skip crowd boxes in training target\n",
    "        klass = klass[is_crowd == 0]\n",
    "        if not len(boxes):\n",
    "            raise MalformedData(\"No valid gt_boxes!\")\n",
    "    except MalformedData as e:\n",
    "        log_once(\"Input {} is filtered for training: {}\".format(fname, str(e)), 'warn')\n",
    "        return None\n",
    "\n",
    "    ret = [im] + list(anchor_inputs) + [boxes, klass]\n",
    "\n",
    "    if cfg.MODE_MASK:\n",
    "        # augmentation will modify the polys in-place\n",
    "        segmentation = copy.deepcopy(img['segmentation'])\n",
    "        segmentation = [segmentation[k] for k in range(len(segmentation)) if not is_crowd[k]]\n",
    "        assert len(segmentation) == len(boxes)\n",
    "\n",
    "        # Apply augmentation on polygon coordinates.\n",
    "        # And produce one image-sized binary mask per box.\n",
    "        masks = []\n",
    "        for polys in segmentation:\n",
    "            polys = [aug.augment_coords(p, params) for p in polys]\n",
    "            masks.append(segmentation_to_mask(polys, im.shape[0], im.shape[1]))\n",
    "        masks = np.asarray(masks, dtype='uint8')    # values in {0, 1}\n",
    "        ret.append(masks)\n",
    "\n",
    "        # from viz import draw_annotation, draw_mask\n",
    "        # viz = draw_annotation(im, boxes, klass)\n",
    "        # for mask in masks:\n",
    "        #     viz = draw_mask(viz, mask)\n",
    "        # tpviz.interactive_imshow(viz)\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.reset_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dp in ds.get_data():\n",
    "    break\n",
    "dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = preprocess(dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, 5, (800, 1067, 3))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ret), len(ret), ret[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((84, 84, 15), (84, 84, 15, 4), (1, 4), (1,))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret[1].shape, ret[2].shape, ret[3].shape, ret[4].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test dump cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_dict = cfg.to_dict()\n",
    "\n",
    "import json\n",
    "\n",
    "with open(\"config.json\", \"w\") as h:\n",
    "    json.dump(conf_dict, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
