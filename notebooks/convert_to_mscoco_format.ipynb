{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert annotations to MS Coco format with more meta fields\n",
    "\n",
    "Convert datasets: validation and test\n",
    "```\n",
    "test (108159) + 70% validation (25147) -> train\n",
    "30% validation (10777) -> val\n",
    "```\n",
    "We added into annotations:\n",
    "- 'IsOccluded'\n",
    "- 'IsTruncated'\n",
    "- 'IsDepiction'\n",
    "- 'IsInside'\n",
    "\n",
    "Apply prefiltering: \n",
    "- images with any dimension larger 2000 pixels are ignored\n",
    "- do not write annotations without bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from pathlib import Path\n",
    "except ImportError:\n",
    "    from pathlib2 import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import json\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_IMAGES_PATH = Path(\".\").resolve().parent / \"input\" / \"validation\"\n",
    "VALIDATION_ANNOTATIONS_CSV_PATH = Path(\".\").resolve().parent / \"input\" / \"validation-annotations-bbox.csv\"\n",
    "VALIDATION_CONFIDENCE_CSV_PATH = Path(\".\").resolve().parent / \"input\" / \"validation-annotations-human-imagelabels-boxable.csv\"\n",
    "VALIDATION_IMGINFO_CSV_PATH = Path(\".\").resolve().parent / \"input\" / \"validation-images-with-rotation.csv\"\n",
    "LABELS_DESCRIPTION_CSV_PATH = Path(\".\").resolve().parent / \"input\" / \"class-descriptions-boxable.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_IMAGES_PATH = Path(\".\").resolve().parent / \"input\" / \"test\"\n",
    "TEST_ANNOTATIONS_CSV_PATH = Path(\".\").resolve().parent / \"input\" / \"test-annotations-bbox.csv\"\n",
    "TEST_CONFIDENCE_CSV_PATH = Path(\".\").resolve().parent / \"input\" / \"test-annotations-human-imagelabels-boxable.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_description = pd.read_csv(LABELS_DESCRIPTION_CSV_PATH, header=None)\n",
    "labels = labels_description[1].values.tolist()\n",
    "\n",
    "coco_categories = []\n",
    "for i, label in enumerate(labels):\n",
    "    coco_categories.append({\n",
    "        'id': i,\n",
    "        'name': label,\n",
    "        'supercategory': label\n",
    "    })\n",
    "    \n",
    "categories = {}\n",
    "for d in coco_categories:\n",
    "    categories[d['name']] = d['id']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "xyxy_cols = ['XMin', 'YMin', 'XMax', 'YMax']\n",
    "meta_cols = ['IsOccluded', 'IsTruncated', 'IsGroupOf', 'IsDepiction', 'IsInside']\n",
    "ignore_is_crowd = True\n",
    "\n",
    "\n",
    "def get_bboxes_labels_meta(canvas_size, image_id):\n",
    "    bboxes = annotations.loc[image_id, xyxy_cols].values\n",
    "    labels = annotations.loc[image_id, 'LabelName']\n",
    "    meta = annotations.loc[image_id, meta_cols].values\n",
    "    \n",
    "    if bboxes.ndim == 1:\n",
    "        bboxes = bboxes[None, :]\n",
    "        meta = meta[None, :]\n",
    "    \n",
    "    if isinstance(labels, str):        \n",
    "        labels = np.array([labels, ])\n",
    "        \n",
    "    # BBox format should be (x, y, w, h)\n",
    "    bboxes[:, 0] *= canvas_size[0]\n",
    "    bboxes[:, 1] *= canvas_size[1]\n",
    "    \n",
    "    bboxes[:, 2] *= canvas_size[0]\n",
    "    bboxes[:, 2] -= bboxes[:, 0]\n",
    "    \n",
    "    bboxes[:, 3] *= canvas_size[1]\n",
    "    bboxes[:, 3] -= bboxes[:, 1]\n",
    "    return bboxes, labels, meta\n",
    "\n",
    "\n",
    "def compute_area(bbox):\n",
    "    return bbox[2] * bbox[3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create validation dataset:\n",
    "\n",
    "- 30% validation (10777)\n",
    "\n",
    "\n",
    "Create train dataset:\n",
    "\n",
    "- 70% validation (25147)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = VALIDATION_IMAGES_PATH\n",
    "annotations_path = VALIDATION_ANNOTATIONS_CSV_PATH\n",
    "output_mode = \"val_0.1\"\n",
    "\n",
    "\n",
    "annotations = pd.read_csv(annotations_path, index_col=\"ImageID\")\n",
    "annotations['LabelName'] = annotations['LabelName'].map(labels_description.set_index(0)[1])\n",
    "image_ids = annotations.index.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "train_image_ids, val_image_ids = train_test_split(image_ids, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_images = []\n",
    "coco_annotations = []\n",
    "\n",
    "\n",
    "for image_id in val_image_ids:\n",
    "    img = Image.open(images_path / \"{}.jpg\".format(image_id))\n",
    "    \n",
    "    if max(img.size) > 2000 or min(img.size) < 100:\n",
    "        continue\n",
    "    \n",
    "    image_info = {\n",
    "            \"id\": image_id,\n",
    "            \"file_name\": \"{}.jpg\".format(image_id),\n",
    "            \"width\": img.size[0],\n",
    "            \"height\": img.size[1],\n",
    "    }    \n",
    "    bboxes, labels, meta = get_bboxes_labels_meta(img.size, image_id)\n",
    "    \n",
    "    if len(bboxes) == 0:\n",
    "        print(\"No bboxes for image_id '{}'\".format(image_id))\n",
    "        continue\n",
    "\n",
    "    coco_images.append(image_info)    \n",
    "    for i, (bbox, label, m) in enumerate(zip(bboxes, labels, meta)):\n",
    "        m = [int(v) for v in m]\n",
    "        annotation_id = hash(image_id + \"_{}\".format(i))\n",
    "        annotation_info = {\n",
    "            \"id\": annotation_id,\n",
    "            \"image_id\": image_id,\n",
    "            \"category_id\": categories[label],\n",
    "            \"IsOccluded\": m[0],\n",
    "            \"IsTruncated\": m[1],\n",
    "            \"iscrowd\": m[2] if not ignore_is_crowd else 0,\n",
    "            \"IsDepiction\": m[3],\n",
    "            \"IsInside\": m[4],            \n",
    "            \"area\": int(compute_area(bbox)),\n",
    "            \"bbox\": [int(v) for v in bbox.tolist()],\n",
    "            \"segmentation\": [],\n",
    "        } \n",
    "        coco_annotations.append(annotation_info)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3587, 21081)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(coco_images), len(coco_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_coco_annotations = {\n",
    "    \"categories\": coco_categories,\n",
    "    \"images\": coco_images,\n",
    "    \"annotations\": coco_annotations\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = Path(\".\").resolve().parent / \"input\" / \"as_mscoco\" / \"annotations\" \n",
    "if not output_folder.exists():\n",
    "    output_folder.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open((output_folder / \"{}.json\".format(output_mode)).as_posix(), 'w') as h:\n",
    "    json.dump(output_coco_annotations, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_mode = \"val_0.9\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_images = []\n",
    "coco_annotations = []\n",
    "\n",
    "\n",
    "for image_id in train_image_ids:\n",
    "    img = Image.open(images_path / \"{}.jpg\".format(image_id))\n",
    "    \n",
    "    if max(img.size) > 2000 or min(img.size) < 100:\n",
    "        continue\n",
    "    \n",
    "    image_info = {\n",
    "            \"id\": image_id,\n",
    "            \"file_name\": \"{}.jpg\".format(image_id),\n",
    "            \"width\": img.size[0],\n",
    "            \"height\": img.size[1],\n",
    "    }    \n",
    "    bboxes, labels, meta = get_bboxes_labels_meta(img.size, image_id)\n",
    "    \n",
    "    if len(bboxes) == 0:\n",
    "        print(\"No bboxes for image_id '{}'\".format(image_id))\n",
    "        continue\n",
    "\n",
    "    coco_images.append(image_info)    \n",
    "    for i, (bbox, label, m) in enumerate(zip(bboxes, labels, meta)):\n",
    "        m = [int(v) for v in m]\n",
    "        annotation_id = hash(image_id + \"_{}\".format(i))\n",
    "        annotation_info = {\n",
    "            \"id\": annotation_id,\n",
    "            \"image_id\": image_id,\n",
    "            \"category_id\": categories[label],\n",
    "            \"IsOccluded\": m[0],\n",
    "            \"IsTruncated\": m[1],\n",
    "            \"iscrowd\": m[2] if not ignore_is_crowd else 0,\n",
    "            \"IsDepiction\": m[3],\n",
    "            \"IsInside\": m[4],            \n",
    "            \"area\": int(compute_area(bbox)),\n",
    "            \"bbox\": [int(v) for v in bbox.tolist()],\n",
    "            \"segmentation\": [],\n",
    "        } \n",
    "        coco_annotations.append(annotation_info)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32286, 183352)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(coco_images), len(coco_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_coco_annotations = {\n",
    "    \"categories\": coco_categories,\n",
    "    \"images\": coco_images,\n",
    "    \"annotations\": coco_annotations\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = Path(\".\").resolve().parent / \"input\" / \"as_mscoco\" / \"annotations\" \n",
    "if not output_folder.exists():\n",
    "    output_folder.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open((output_folder / \"{}.json\".format(output_mode)).as_posix(), 'w') as h:\n",
    "    json.dump(output_coco_annotations, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_mode = \"val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_images = []\n",
    "coco_annotations = []\n",
    "\n",
    "\n",
    "for image_id in image_ids:\n",
    "    img = Image.open(images_path / \"{}.jpg\".format(image_id))\n",
    "    \n",
    "    if max(img.size) > 2000 or min(img.size) < 100:\n",
    "        continue\n",
    "    \n",
    "    image_info = {\n",
    "            \"id\": image_id,\n",
    "            \"file_name\": \"{}.jpg\".format(image_id),\n",
    "            \"width\": img.size[0],\n",
    "            \"height\": img.size[1],\n",
    "    }    \n",
    "    bboxes, labels, meta = get_bboxes_labels_meta(img.size, image_id)\n",
    "    \n",
    "    if len(bboxes) == 0:\n",
    "        print(\"No bboxes for image_id '{}'\".format(image_id))\n",
    "        continue\n",
    "\n",
    "    coco_images.append(image_info)    \n",
    "    for i, (bbox, label, m) in enumerate(zip(bboxes, labels, meta)):\n",
    "        m = [int(v) for v in m]\n",
    "        annotation_id = hash(image_id + \"_{}\".format(i))\n",
    "        annotation_info = {\n",
    "            \"id\": annotation_id,\n",
    "            \"image_id\": image_id,\n",
    "            \"category_id\": categories[label],\n",
    "            \"IsOccluded\": m[0],\n",
    "            \"IsTruncated\": m[1],\n",
    "            \"iscrowd\": m[2] if not ignore_is_crowd else 0,\n",
    "            \"IsDepiction\": m[3],\n",
    "            \"IsInside\": m[4],            \n",
    "            \"area\": int(compute_area(bbox)),\n",
    "            \"bbox\": [int(v) for v in bbox.tolist()],\n",
    "            \"segmentation\": [],\n",
    "        } \n",
    "        coco_annotations.append(annotation_info)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35873, 204433)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(coco_images), len(coco_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_coco_annotations = {\n",
    "    \"categories\": coco_categories,\n",
    "    \"images\": coco_images,\n",
    "    \"annotations\": coco_annotations\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = Path(\".\").resolve().parent / \"input\" / \"as_mscoco\" / \"annotations\" \n",
    "if not output_folder.exists():\n",
    "    output_folder.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open((output_folder / \"{}.json\".format(output_mode)).as_posix(), 'w') as h:\n",
    "    json.dump(output_coco_annotations, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create train dataset:\n",
    "\n",
    "- test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = TEST_IMAGES_PATH\n",
    "annotations_path = TEST_ANNOTATIONS_CSV_PATH\n",
    "output_mode = \"test\"\n",
    "\n",
    "annotations = pd.read_csv(annotations_path, index_col=\"ImageID\")\n",
    "annotations['LabelName'] = annotations['LabelName'].map(labels_description.set_index(0)[1])\n",
    "image_ids = annotations.index.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/PIL/Image.py:2509: DecompressionBombWarning: Image size (102539736 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning)\n"
     ]
    }
   ],
   "source": [
    "coco_images = []\n",
    "coco_annotations = []\n",
    "\n",
    "\n",
    "for image_id in image_ids:    \n",
    "    img = Image.open(images_path / \"{}.jpg\".format(image_id))\n",
    "    \n",
    "    if max(img.size) > 2000 or min(img.size) < 100:\n",
    "        continue\n",
    "    \n",
    "    image_info = {\n",
    "            \"id\": image_id,\n",
    "            \"file_name\": \"{}.jpg\".format(image_id),\n",
    "            \"width\": img.size[0],\n",
    "            \"height\": img.size[1],\n",
    "    }    \n",
    "    bboxes, labels, meta = get_bboxes_labels_meta(img.size, image_id)\n",
    "    \n",
    "    if len(bboxes) == 0:\n",
    "        print(\"No bboxes for image_id '{}'\".format(image_id))\n",
    "        continue\n",
    "\n",
    "    coco_images.append(image_info)    \n",
    "    for i, (bbox, label, m) in enumerate(zip(bboxes, labels, meta)):\n",
    "        m = [int(v) for v in m]\n",
    "        annotation_id = hash(image_id + \"_{}\".format(i))\n",
    "        annotation_info = {\n",
    "            \"id\": annotation_id,\n",
    "            \"image_id\": image_id,\n",
    "            \"category_id\": categories[label],\n",
    "            \"IsOccluded\": m[0],\n",
    "            \"IsTruncated\": m[1],\n",
    "            \"iscrowd\": m[2] if not ignore_is_crowd else 0,\n",
    "            \"IsDepiction\": m[3],\n",
    "            \"IsInside\": m[4],            \n",
    "            \"area\": int(compute_area(bbox)),\n",
    "            \"bbox\": [int(v) for v in bbox.tolist()],\n",
    "            \"segmentation\": [],\n",
    "        } \n",
    "        coco_annotations.append(annotation_info)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107988, 624169)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(coco_images), len(coco_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_coco_annotations = {\n",
    "    \"categories\": coco_categories,\n",
    "    \"images\": coco_images,\n",
    "    \"annotations\": coco_annotations\n",
    "}\n",
    "\n",
    "\n",
    "output_folder = Path(\".\").resolve().parent / \"input\" / \"as_mscoco\" / \"annotations\" \n",
    "if not output_folder.exists():\n",
    "    output_folder.mkdir(parents=True)\n",
    "    \n",
    "    \n",
    "with open((output_folder / \"{}.json\".format(output_mode)).as_posix(), 'w') as h:\n",
    "    json.dump(output_coco_annotations, h)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create train dataset to check overfitting\n",
    "\n",
    "- 10 images from test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = TEST_IMAGES_PATH\n",
    "annotations_path = TEST_ANNOTATIONS_CSV_PATH\n",
    "output_mode = \"train_overfit\"\n",
    "\n",
    "annotations = pd.read_csv(annotations_path, index_col=\"ImageID\")\n",
    "annotations['LabelName'] = annotations['LabelName'].map(labels_description.set_index(0)[1])\n",
    "image_ids = annotations.index.unique()\n",
    "image_ids = image_ids[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_images = []\n",
    "coco_annotations = []\n",
    "\n",
    "\n",
    "for image_id in image_ids:    \n",
    "    img = Image.open(images_path / \"{}.jpg\".format(image_id))\n",
    "    \n",
    "    if max(img.size) > 2000 or min(img.size) < 100:\n",
    "        continue\n",
    "    \n",
    "    image_info = {\n",
    "            \"id\": image_id,\n",
    "            \"file_name\": \"{}.jpg\".format(image_id),\n",
    "            \"width\": img.size[0],\n",
    "            \"height\": img.size[1],\n",
    "    }    \n",
    "    bboxes, labels, meta = get_bboxes_labels_meta(img.size, image_id)\n",
    "    \n",
    "    if len(bboxes) == 0:\n",
    "        print(\"No bboxes for image_id '{}'\".format(image_id))\n",
    "        continue\n",
    "\n",
    "    coco_images.append(image_info)    \n",
    "    for i, (bbox, label, m) in enumerate(zip(bboxes, labels, meta)):\n",
    "        m = [int(v) for v in m]\n",
    "        annotation_id = hash(image_id + \"_{}\".format(i))\n",
    "        annotation_info = {\n",
    "            \"id\": annotation_id,\n",
    "            \"image_id\": image_id,\n",
    "            \"category_id\": categories[label],\n",
    "            \"IsOccluded\": m[0],\n",
    "            \"IsTruncated\": m[1],\n",
    "            \"iscrowd\": m[2] if not ignore_is_crowd else 0,\n",
    "            \"IsDepiction\": m[3],\n",
    "            \"IsInside\": m[4],            \n",
    "            \"area\": int(compute_area(bbox)),\n",
    "            \"bbox\": [int(v) for v in bbox.tolist()],\n",
    "            \"segmentation\": [],\n",
    "        } \n",
    "        coco_annotations.append(annotation_info)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 68)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(coco_images), len(coco_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_coco_annotations = {\n",
    "    \"categories\": coco_categories,\n",
    "    \"images\": coco_images,\n",
    "    \"annotations\": coco_annotations\n",
    "}\n",
    "\n",
    "\n",
    "output_folder = Path(\".\").resolve().parent / \"input\" / \"as_mscoco\" / \"annotations\" \n",
    "if not output_folder.exists():\n",
    "    output_folder.mkdir(parents=True)\n",
    "    \n",
    "    \n",
    "with open((output_folder / \"{}.json\".format(output_mode)).as_posix(), 'w') as h:\n",
    "    json.dump(output_coco_annotations, h)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create symlinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_mode = \"val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_images_folder = Path(\".\").resolve().parent / \"input\" / \"as_mscoco\" / output_mode\n",
    "if not output_images_folder.exists():\n",
    "    output_images_folder.symlink_to(images_path, target_is_directory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_mode = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_images_folder = Path(\".\").resolve().parent / \"input\" / \"as_mscoco\" / output_mode\n",
    "if not output_images_folder.exists():\n",
    "    output_images_folder.symlink_to(images_path, target_is_directory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_mode = \"train_overfit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_images_folder = Path(\".\").resolve().parent / \"input\" / \"as_mscoco\" / output_mode\n",
    "\n",
    "if not output_images_folder.exists():\n",
    "    output_images_folder.mkdir()\n",
    "\n",
    "for image_id in image_ids:\n",
    "    !ln -s {images_path.as_posix()}/{image_id}.jpg {output_images_folder}/{image_id}.jpg \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000026e7ee790996.jpg  0002ab0af02e4a77.jpg  00045d609ca3f4eb.jpg\n",
      "000062a39995e348.jpg  0002cc8afaf1b611.jpg  00068d5450f0358b.jpg\n",
      "0000c64e1253d68f.jpg  0003d84e0165d630.jpg\n",
      "000132c20b84269b.jpg  000411001ff7dd4f.jpg\n"
     ]
    }
   ],
   "source": [
    "!ls {output_images_folder}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test with pycocotools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools import coco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.37s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "output_folder = Path(\".\").resolve().parent / \"input\" / \"as_mscoco\" / \"annotations\" \n",
    "\n",
    "coco = coco.COCO((output_folder / \"val.json\").as_posix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "anns = coco.getAnnIds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60806, ['1e45fc409ab318ab_0', '1e45fc409ab318ab_1'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(anns), anns[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = coco.getImgIds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10759, ['5840d582ce4fbe93', '21494d2aaaf0d2c1'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imgs), imgs[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'file_name': '5840d582ce4fbe93.jpg',\n",
       "  'height': 683,\n",
       "  'id': '5840d582ce4fbe93',\n",
       "  'width': 1024}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coco.loadImgs(['5840d582ce4fbe93', ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
