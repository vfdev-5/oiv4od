{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert annotations to MS Coco format with more meta fields\n",
    "\n",
    "Convert datasets: train 500k, validation and test\n",
    "\n",
    "We added into annotations:\n",
    "- 'IsOccluded'\n",
    "- 'IsTruncated'\n",
    "- 'IsDepiction'\n",
    "- 'IsInside'\n",
    "\n",
    "Apply prefiltering: \n",
    "- images with any dimension larger 2000 pixels are ignored\n",
    "- do not write annotations without bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "as_mscoco\r\n",
      "class-descriptions-boxable.csv\r\n",
      "info.md\r\n",
      "test\r\n",
      "test-annotations-bbox.csv\r\n",
      "test-annotations-human-imagelabels-boxable.csv\r\n",
      "test-images-with-rotation.csv\r\n",
      "test_challenge_2018\r\n",
      "validation\r\n",
      "validation-annotations-bbox.csv\r\n",
      "validation-annotations-human-imagelabels-boxable.csv\r\n",
      "validation-images-with-rotation.csv\r\n"
     ]
    }
   ],
   "source": [
    "# data_path=\"/home/data\"\n",
    "# !cd ../ && ln -s {data_path} input\n",
    "!ls ../input/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125436\n",
      "41620\n"
     ]
    }
   ],
   "source": [
    "!ls ../input/test | wc -l\n",
    "!ls ../input/validation | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from pathlib import Path\n",
    "except ImportError:\n",
    "    from pathlib2 import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import json\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_IMAGES_PATH = Path(\".\").resolve().parent / \"input\" / \"validation\"\n",
    "VALIDATION_ANNOTATIONS_CSV_PATH = Path(\".\").resolve().parent / \"input\" / \"validation-annotations-bbox.csv\"\n",
    "VALIDATION_CONFIDENCE_CSV_PATH = Path(\".\").resolve().parent / \"input\" / \"validation-annotations-human-imagelabels-boxable.csv\"\n",
    "VALIDATION_IMGINFO_CSV_PATH = Path(\".\").resolve().parent / \"input\" / \"validation-images-with-rotation.csv\"\n",
    "LABELS_DESCRIPTION_CSV_PATH = Path(\".\").resolve().parent / \"input\" / \"class-descriptions-boxable.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_IMAGES_PATH = Path(\".\").resolve().parent / \"input\" / \"test\"\n",
    "TEST_ANNOTATIONS_CSV_PATH = Path(\".\").resolve().parent / \"input\" / \"test-annotations-bbox.csv\"\n",
    "TEST_CONFIDENCE_CSV_PATH = Path(\".\").resolve().parent / \"input\" / \"test-annotations-human-imagelabels-boxable.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_description = pd.read_csv(LABELS_DESCRIPTION_CSV_PATH, header=None)\n",
    "labels = labels_description[1].values.tolist()\n",
    "\n",
    "coco_categories = []\n",
    "for i, label in enumerate(labels):\n",
    "    coco_categories.append({\n",
    "        'id': i,\n",
    "        'name': label,\n",
    "        'supercategory': label\n",
    "    })\n",
    "    \n",
    "categories = {}\n",
    "for d in coco_categories:\n",
    "    categories[d['name']] = d['id']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "xyxy_cols = ['XMin', 'YMin', 'XMax', 'YMax']\n",
    "meta_cols = ['IsOccluded', 'IsTruncated', 'IsGroupOf', 'IsDepiction', 'IsInside']\n",
    "ignore_is_crowd = True\n",
    "\n",
    "\n",
    "def get_bboxes_labels_meta(canvas_size, image_id, annotations):\n",
    "    bboxes = annotations.loc[image_id, xyxy_cols].values\n",
    "    labels = annotations.loc[image_id, 'LabelName']\n",
    "    meta = annotations.loc[image_id, meta_cols].values\n",
    "    \n",
    "    if bboxes.ndim == 1:\n",
    "        bboxes = bboxes[None, :]\n",
    "        meta = meta[None, :]\n",
    "    \n",
    "    if isinstance(labels, str):        \n",
    "        labels = np.array([labels, ])\n",
    "        \n",
    "    # BBox format should be (x, y, w, h)\n",
    "    bboxes[:, 0] *= canvas_size[0]\n",
    "    bboxes[:, 1] *= canvas_size[1]\n",
    "    \n",
    "    bboxes[:, 2] *= canvas_size[0]\n",
    "    bboxes[:, 2] -= bboxes[:, 0]\n",
    "    \n",
    "    bboxes[:, 3] *= canvas_size[1]\n",
    "    bboxes[:, 3] -= bboxes[:, 1]\n",
    "    return bboxes, labels, meta\n",
    "\n",
    "\n",
    "def compute_area(bbox):\n",
    "    return bbox[2] * bbox[3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "\n",
    "def create_annotations_json(images_path, annotations, coco_categories, output_mode, \n",
    "                            image_ids=None, ignore_is_crowd=True):\n",
    "    \n",
    "    coco_images = []\n",
    "    coco_annotations = []\n",
    "    \n",
    "    if image_ids is None:\n",
    "        image_ids = annotations.index.unique()        \n",
    "\n",
    "        \n",
    "    for image_id in tqdm.tqdm(image_ids):\n",
    "        \n",
    "        img = Image.open(images_path / \"{}.jpg\".format(image_id))\n",
    "\n",
    "        if max(img.size) > 2000 or min(img.size) < 100:\n",
    "            continue\n",
    "\n",
    "        image_info = {\n",
    "                \"id\": image_id,\n",
    "                \"file_name\": \"{}.jpg\".format(image_id),\n",
    "                \"width\": img.size[0],\n",
    "                \"height\": img.size[1],\n",
    "        }    \n",
    "        \n",
    "        bboxes, labels, meta = get_bboxes_labels_meta(img.size, image_id, annotations)\n",
    "\n",
    "        if len(bboxes) == 0:\n",
    "            print(\"No bboxes for image_id '{}'\".format(image_id))\n",
    "            continue\n",
    "\n",
    "        coco_images.append(image_info)        \n",
    "   \n",
    "        for i, (bbox, label, m) in enumerate(zip(bboxes, labels, meta)):\n",
    "            m = [int(v) for v in m]\n",
    "            bbox = [int(v) for v in bbox.tolist()]\n",
    "            annotation_id = hash(image_id + \"_{}\".format(i))\n",
    "            annotation_info = {\n",
    "                \"id\": annotation_id,\n",
    "                \"image_id\": image_id,\n",
    "                \"category_id\": categories[label],\n",
    "                \"IsOccluded\": m[0],\n",
    "                \"IsTruncated\": m[1],\n",
    "                \"iscrowd\": m[2] if not ignore_is_crowd else 0,\n",
    "                \"IsDepiction\": m[3],\n",
    "                \"IsInside\": m[4],            \n",
    "                \"area\": int(compute_area(bbox)),\n",
    "                \"bbox\": bbox,\n",
    "                \"segmentation\": [],\n",
    "            } \n",
    "            coco_annotations.append(annotation_info)  \n",
    "\n",
    "    output_coco_annotations = {\n",
    "        \"categories\": coco_categories,\n",
    "        \"images\": coco_images,\n",
    "        \"annotations\": coco_annotations\n",
    "    }\n",
    "    \n",
    "    output_folder = Path(\".\").resolve().parent / \"input\" / \"as_mscoco\" / \"annotations\" \n",
    "    if not output_folder.exists():\n",
    "        output_folder.mkdir(parents=True)\n",
    "    \n",
    "    with open((output_folder / \"{}.json\".format(output_mode)).as_posix(), 'w') as h:\n",
    "        json.dump(output_coco_annotations, h)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create validation dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = VALIDATION_IMAGES_PATH\n",
    "annotations_path = VALIDATION_ANNOTATIONS_CSV_PATH\n",
    "output_mode = \"val\"\n",
    "\n",
    "annotations = pd.read_csv(annotations_path, index_col=\"ImageID\")\n",
    "annotations['LabelName'] = annotations['LabelName'].map(labels_description.set_index(0)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35925/35925 [01:09<00:00, 513.97it/s]\n"
     ]
    }
   ],
   "source": [
    "create_annotations_json(images_path, annotations, coco_categories, output_mode, \n",
    "                        ignore_is_crowd=ignore_is_crowd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = TEST_IMAGES_PATH\n",
    "annotations_path = TEST_ANNOTATIONS_CSV_PATH\n",
    "output_mode = \"test\"\n",
    "\n",
    "annotations = pd.read_csv(annotations_path, index_col=\"ImageID\")\n",
    "annotations['LabelName'] = annotations['LabelName'].map(labels_description.set_index(0)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 45719/108159 [01:29<02:01, 513.20it/s]/usr/local/lib/python2.7/dist-packages/PIL/Image.py:2509: DecompressionBombWarning: Image size (102539736 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning)\n",
      "100%|██████████| 108159/108159 [03:31<00:00, 510.89it/s]\n"
     ]
    }
   ],
   "source": [
    "create_annotations_json(images_path, annotations, coco_categories, output_mode, \n",
    "                        ignore_is_crowd=ignore_is_crowd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create train dataset to check overfitting\n",
    "\n",
    "- 10 images from test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = TEST_IMAGES_PATH\n",
    "annotations_path = TEST_ANNOTATIONS_CSV_PATH\n",
    "output_mode = \"train_overfit\"\n",
    "\n",
    "annotations = pd.read_csv(annotations_path, index_col=\"ImageID\")\n",
    "annotations['LabelName'] = annotations['LabelName'].map(labels_description.set_index(0)[1])\n",
    "image_ids = annotations.index.unique()\n",
    "image_ids = image_ids[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 98.99it/s]\n"
     ]
    }
   ],
   "source": [
    "create_annotations_json(images_path, annotations, coco_categories, output_mode, \n",
    "                        ignore_is_crowd=ignore_is_crowd, image_ids=image_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create symlinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 16\r\n",
      "drwxr-xr-x 4 root root 4096 Jul 28 14:58 .\r\n",
      "drwxrwxrwx 7 1000 1000 4096 Jul 28 11:10 ..\r\n",
      "drwxr-xr-x 2 root root 4096 Jul 28 11:22 annotations\r\n",
      "drwxr-xr-x 2 root root 4096 Jul 28 11:22 train_overfit\r\n"
     ]
    }
   ],
   "source": [
    "!ls -all ../input/as_mscoco/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_mode = \"val\"\n",
    "images_path = VALIDATION_IMAGES_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_images_folder = Path(\".\").resolve().parent / \"input\" / \"as_mscoco\" / output_mode\n",
    "if not output_images_folder.exists():\n",
    "    output_images_folder.symlink_to(images_path, target_is_directory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_mode = \"test\"\n",
    "images_path = TEST_IMAGES_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_images_folder = Path(\".\").resolve().parent / \"input\" / \"as_mscoco\" / output_mode\n",
    "if not output_images_folder.exists():\n",
    "    output_images_folder.symlink_to(images_path, target_is_directory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_mode = \"train_overfit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_images_folder = Path(\".\").resolve().parent / \"input\" / \"as_mscoco\" / output_mode\n",
    "\n",
    "if not output_images_folder.exists():\n",
    "    output_images_folder.mkdir()\n",
    "\n",
    "for image_id in image_ids:\n",
    "    !ln -s {images_path.as_posix()}/{image_id}.jpg {output_images_folder}/{image_id}.jpg \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000026e7ee790996.jpg  0002ab0af02e4a77.jpg  00045d609ca3f4eb.jpg\r\n",
      "000062a39995e348.jpg  0002cc8afaf1b611.jpg  00068d5450f0358b.jpg\r\n",
      "0000c64e1253d68f.jpg  0003d84e0165d630.jpg\r\n",
      "000132c20b84269b.jpg  000411001ff7dd4f.jpg\r\n"
     ]
    }
   ],
   "source": [
    "!ls {output_images_folder}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 16\r\n",
      "drwxr-xr-x 4 root root 4096 Jul 28 14:58 .\r\n",
      "drwxrwxrwx 7 1000 1000 4096 Jul 28 11:10 ..\r\n",
      "drwxr-xr-x 2 root root 4096 Jul 28 11:22 annotations\r\n",
      "lrwxrwxrwx 1 root root   31 Jul 28 14:58 test -> /home/project/oiv4od/input/test\r\n",
      "drwxr-xr-x 2 root root 4096 Jul 28 11:22 train_overfit\r\n",
      "lrwxrwxrwx 1 root root   37 Jul 28 14:58 val -> /home/project/oiv4od/input/validation\r\n"
     ]
    }
   ],
   "source": [
    "!ls -all ../input/as_mscoco/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test with pycocotools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools import coco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=6.48s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "output_folder = Path(\".\").resolve().parent / \"input\" / \"as_mscoco\" / \"annotations\" \n",
    "\n",
    "coco = coco.COCO((output_folder / \"test.json\").as_posix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ids = coco.getImgIds()\n",
    "image_ids.sort()\n",
    "roidb = coco.loadImgs(image_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, 215976)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(roidb), len(roidb) * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'file_name': '5840d582ce4fbe93.jpg',\n",
       "  'height': 683,\n",
       "  'id': '5840d582ce4fbe93',\n",
       "  'width': 1024}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coco.loadImgs(['5840d582ce4fbe93', ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check complete datasets on errors:\n",
    "- no annotations, \n",
    "- annotation has zero or negative size\n",
    "- annotation is out of bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "output_folder = Path(\".\").resolve().parent / \"input\" / \"as_mscoco\" / \"annotations\" \n",
    "annotations_file = output_folder / \"test.json\"\n",
    "\n",
    "with open(annotations_file.as_posix(), 'r') as h:\n",
    "    annotations = json.load(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_images = {}\n",
    "for im in annotations['images']:\n",
    "    annotations_images[im['id']] = im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Found zero bbox: ', {u'IsTruncated': 0, u'segmentation': [], u'area': 0, u'iscrowd': 0, u'IsInside': 0, u'IsOccluded': 0, u'image_id': u'330aa8283c3f543f', u'bbox': [693, 294, 39, 0], u'IsDepiction': 0, u'category_id': 42, u'id': -8855916499609862000})\n",
      "('Found zero bbox: ', {u'IsTruncated': 0, u'segmentation': [], u'area': 0, u'iscrowd': 0, u'IsInside': 0, u'IsOccluded': 0, u'image_id': u'36a8935e3b98fda6', u'bbox': [191, 366, 0, 2], u'IsDepiction': 0, u'category_id': 276, u'id': -2008481524992296630})\n",
      "('Found zero bbox: ', {u'IsTruncated': 0, u'segmentation': [], u'area': 0, u'iscrowd': 0, u'IsInside': 0, u'IsOccluded': 0, u'image_id': u'3a1a866065696e51', u'bbox': [699, 269, 5, 0], u'IsDepiction': 0, u'category_id': 433, u'id': -2141126454031441549})\n",
      "('Found zero bbox: ', {u'IsTruncated': 0, u'segmentation': [], u'area': 0, u'iscrowd': 0, u'IsInside': 0, u'IsOccluded': 0, u'image_id': u'4e416d4066440a8f', u'bbox': [61, 313, 9, 0], u'IsDepiction': 0, u'category_id': 252, u'id': 5130305545696726025})\n",
      "('Found zero bbox: ', {u'IsTruncated': 0, u'segmentation': [], u'area': 0, u'iscrowd': 0, u'IsInside': 0, u'IsOccluded': 0, u'image_id': u'4e416d4066440a8f', u'bbox': [520, 342, 1, 0], u'IsDepiction': 0, u'category_id': 252, u'id': 5130305545698726039})\n",
      "('Found zero bbox: ', {u'IsTruncated': 0, u'segmentation': [], u'area': 0, u'iscrowd': 0, u'IsInside': 0, u'IsOccluded': 0, u'image_id': u'6c39b8f6227fce1b', u'bbox': [124, 525, 1, 0], u'IsDepiction': 0, u'category_id': 567, u'id': -7104323863004421882})\n",
      "('Found zero bbox: ', {u'IsTruncated': 1, u'segmentation': [], u'area': 0, u'iscrowd': 0, u'IsInside': 0, u'IsOccluded': 0, u'image_id': u'7275799fb4fcfd42', u'bbox': [0, 401, 0, 5], u'IsDepiction': 0, u'category_id': 567, u'id': 5658958641013070563})\n",
      "('Found zero bbox: ', {u'IsTruncated': 1, u'segmentation': [], u'area': 0, u'iscrowd': 0, u'IsInside': 0, u'IsOccluded': 0, u'image_id': u'7275799fb4fcfd42', u'bbox': [776, 0, 5, 0], u'IsDepiction': 0, u'category_id': 567, u'id': -5848579180367235019})\n",
      "('Found zero bbox: ', {u'IsTruncated': 0, u'segmentation': [], u'area': 0, u'iscrowd': 0, u'IsInside': 0, u'IsOccluded': 0, u'image_id': u'87610612ebf92192', u'bbox': [464, 413, 0, 3], u'IsDepiction': 0, u'category_id': 276, u'id': -2042241559664012850})\n",
      "('Found zero bbox: ', {u'IsTruncated': 0, u'segmentation': [], u'area': 0, u'iscrowd': 0, u'IsInside': 0, u'IsOccluded': 0, u'image_id': u'87610612ebf92192', u'bbox': [492, 400, 0, 0], u'IsDepiction': 0, u'category_id': 276, u'id': -2042241559664012849})\n",
      "('Found zero bbox: ', {u'IsTruncated': 0, u'segmentation': [], u'area': 0, u'iscrowd': 0, u'IsInside': 0, u'IsOccluded': 0, u'image_id': u'87610612ebf92192', u'bbox': [501, 400, 3, 0], u'IsDepiction': 0, u'category_id': 276, u'id': -2042241559664012864})\n",
      "('Found zero bbox: ', {u'IsTruncated': 0, u'segmentation': [], u'area': 0, u'iscrowd': 0, u'IsInside': 0, u'IsOccluded': 0, u'image_id': u'909264e66d3f6e7f', u'bbox': [988, 288, 6, 0], u'IsDepiction': 0, u'category_id': 433, u'id': 2971049578340026893})\n",
      "('Found zero bbox: ', {u'IsTruncated': 0, u'segmentation': [], u'area': 0, u'iscrowd': 0, u'IsInside': 0, u'IsOccluded': 0, u'image_id': u'c04e97a5e46eb242', u'bbox': [894, 191, 0, 3], u'IsDepiction': 1, u'category_id': 14, u'id': 6958109296787253288})\n",
      "('Found zero bbox: ', {u'IsTruncated': 0, u'segmentation': [], u'area': 0, u'iscrowd': 0, u'IsInside': 0, u'IsOccluded': 0, u'image_id': u'd9faa7f62b191996', u'bbox': [430, 655, 2, 0], u'IsDepiction': 0, u'category_id': 14, u'id': -7328821028688810025})\n"
     ]
    }
   ],
   "source": [
    "for a in annotations['annotations']:\n",
    "    bbox = a['bbox']\n",
    "    img_info = annotations_images[a['image_id']]\n",
    "    w = img_info['width']\n",
    "    h = img_info['height']\n",
    "    assert 0 <= bbox[0] <= w, \"Problem with {}, {}\".format(a, img_info)\n",
    "    assert 0 <= bbox[1] <= h, \"Problem with {}, {}\".format(a, img_info)\n",
    "    assert 0 <= bbox[0] + bbox[2] <= w, \"Problem with {}, {}\".format(a, img_info)\n",
    "    assert 0 <= bbox[1] + bbox[3] <= h, \"Problem with {}, {}\".format(a, img_info)\n",
    "    if bbox[2] < 1 or bbox[3] < 1:\n",
    "        print(\"Found zero bbox: \", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(624169, 107988)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(annotations['annotations']), len(annotations['images'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = VALIDATION_IMAGES_PATH\n",
    "annotations_path = VALIDATION_ANNOTATIONS_CSV_PATH\n",
    "\n",
    "annotations = pd.read_csv(annotations_path, index_col=\"ImageID\")\n",
    "annotations['LabelName'] = annotations['LabelName'].map(labels_description.set_index(0)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_id = \"a2f7ab86fb274aa0\"\n",
    "\n",
    "img = Image.open(images_path / \"{}.jpg\".format(image_id))\n",
    "\n",
    "if max(img.size) > 2000 or min(img.size) < 100:\n",
    "    raise RuntimeError(\"\")\n",
    "\n",
    "image_info = {\n",
    "        \"id\": image_id,\n",
    "        \"file_name\": \"{}.jpg\".format(image_id),\n",
    "        \"width\": img.size[0],\n",
    "        \"height\": img.size[1],\n",
    "}    \n",
    "bboxes, labels, meta = get_bboxes_labels_meta(img.size, image_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_annotations = []\n",
    "for i, (bbox, label, m) in enumerate(zip(bboxes, labels, meta)):\n",
    "    m = [int(v) for v in m]\n",
    "    bbox = [int(v) for v in bbox.tolist()]\n",
    "    annotation_id = hash(image_id + \"_{}\".format(i))\n",
    "    annotation_info = {\n",
    "        \"id\": annotation_id,\n",
    "        \"image_id\": image_id,\n",
    "        \"category_id\": categories[label],\n",
    "        \"IsOccluded\": m[0],\n",
    "        \"IsTruncated\": m[1],\n",
    "        \"iscrowd\": m[2] if not ignore_is_crowd else 0,\n",
    "        \"IsDepiction\": m[3],\n",
    "        \"IsInside\": m[4],            \n",
    "        \"area\": int(compute_area(bbox)),\n",
    "        \"bbox\": bbox,\n",
    "        \"segmentation\": [],\n",
    "    }\n",
    "    coco_annotations.append(annotation_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'IsDepiction': 1,\n",
       "  'IsInside': 0,\n",
       "  'IsOccluded': 0,\n",
       "  'IsTruncated': 0,\n",
       "  'area': 132,\n",
       "  'bbox': [127, 711, 11, 12],\n",
       "  'category_id': 14,\n",
       "  'id': -9011256856298810697,\n",
       "  'image_id': 'a2f7ab86fb274aa0',\n",
       "  'iscrowd': 0,\n",
       "  'segmentation': []},\n",
       " {'IsDepiction': 1,\n",
       "  'IsInside': 0,\n",
       "  'IsOccluded': 0,\n",
       "  'IsTruncated': 0,\n",
       "  'area': 180,\n",
       "  'bbox': [131, 461, 10, 18],\n",
       "  'category_id': 14,\n",
       "  'id': -9011256856298810698,\n",
       "  'image_id': 'a2f7ab86fb274aa0',\n",
       "  'iscrowd': 0,\n",
       "  'segmentation': []},\n",
       " {'IsDepiction': 1,\n",
       "  'IsInside': 0,\n",
       "  'IsOccluded': 0,\n",
       "  'IsTruncated': 0,\n",
       "  'area': 96,\n",
       "  'bbox': [133, 492, 8, 12],\n",
       "  'category_id': 14,\n",
       "  'id': -9011256856298810699,\n",
       "  'image_id': 'a2f7ab86fb274aa0',\n",
       "  'iscrowd': 0,\n",
       "  'segmentation': []},\n",
       " {'IsDepiction': 1,\n",
       "  'IsInside': 0,\n",
       "  'IsOccluded': 0,\n",
       "  'IsTruncated': 0,\n",
       "  'area': 150,\n",
       "  'bbox': [134, 738, 10, 15],\n",
       "  'category_id': 14,\n",
       "  'id': -9011256856298810700,\n",
       "  'image_id': 'a2f7ab86fb274aa0',\n",
       "  'iscrowd': 0,\n",
       "  'segmentation': []},\n",
       " {'IsDepiction': 1,\n",
       "  'IsInside': 0,\n",
       "  'IsOccluded': 0,\n",
       "  'IsTruncated': 0,\n",
       "  'area': 20,\n",
       "  'bbox': [300, 416, 4, 5],\n",
       "  'category_id': 14,\n",
       "  'id': -9011256856298810701,\n",
       "  'image_id': 'a2f7ab86fb274aa0',\n",
       "  'iscrowd': 0,\n",
       "  'segmentation': []},\n",
       " {'IsDepiction': 1,\n",
       "  'IsInside': 0,\n",
       "  'IsOccluded': 0,\n",
       "  'IsTruncated': 0,\n",
       "  'area': 16,\n",
       "  'bbox': [302, 426, 4, 4],\n",
       "  'category_id': 14,\n",
       "  'id': -9011256856298810702,\n",
       "  'image_id': 'a2f7ab86fb274aa0',\n",
       "  'iscrowd': 0,\n",
       "  'segmentation': []},\n",
       " {'IsDepiction': 1,\n",
       "  'IsInside': 0,\n",
       "  'IsOccluded': 0,\n",
       "  'IsTruncated': 0,\n",
       "  'area': 25,\n",
       "  'bbox': [313, 478, 5, 5],\n",
       "  'category_id': 14,\n",
       "  'id': -9011256856298810703,\n",
       "  'image_id': 'a2f7ab86fb274aa0',\n",
       "  'iscrowd': 0,\n",
       "  'segmentation': []},\n",
       " {'IsDepiction': 1,\n",
       "  'IsInside': 0,\n",
       "  'IsOccluded': 0,\n",
       "  'IsTruncated': 0,\n",
       "  'area': 24,\n",
       "  'bbox': [314, 487, 4, 6],\n",
       "  'category_id': 14,\n",
       "  'id': -9011256856298810704,\n",
       "  'image_id': 'a2f7ab86fb274aa0',\n",
       "  'iscrowd': 0,\n",
       "  'segmentation': []},\n",
       " {'IsDepiction': 1,\n",
       "  'IsInside': 0,\n",
       "  'IsOccluded': 0,\n",
       "  'IsTruncated': 0,\n",
       "  'area': 35,\n",
       "  'bbox': [371, 482, 5, 7],\n",
       "  'category_id': 14,\n",
       "  'id': -9011256856298810689,\n",
       "  'image_id': 'a2f7ab86fb274aa0',\n",
       "  'iscrowd': 0,\n",
       "  'segmentation': []},\n",
       " {'IsDepiction': 1,\n",
       "  'IsInside': 0,\n",
       "  'IsOccluded': 0,\n",
       "  'IsTruncated': 0,\n",
       "  'area': 30,\n",
       "  'bbox': [371, 472, 6, 5],\n",
       "  'category_id': 14,\n",
       "  'id': -9011256856298810690,\n",
       "  'image_id': 'a2f7ab86fb274aa0',\n",
       "  'iscrowd': 0,\n",
       "  'segmentation': []},\n",
       " {'IsDepiction': 1,\n",
       "  'IsInside': 0,\n",
       "  'IsOccluded': 0,\n",
       "  'IsTruncated': 0,\n",
       "  'area': 16,\n",
       "  'bbox': [382, 412, 4, 4],\n",
       "  'category_id': 14,\n",
       "  'id': 5930169957480638671,\n",
       "  'image_id': 'a2f7ab86fb274aa0',\n",
       "  'iscrowd': 0,\n",
       "  'segmentation': []},\n",
       " {'IsDepiction': 1,\n",
       "  'IsInside': 0,\n",
       "  'IsOccluded': 0,\n",
       "  'IsTruncated': 0,\n",
       "  'area': 30,\n",
       "  'bbox': [382, 401, 6, 5],\n",
       "  'category_id': 14,\n",
       "  'id': 5930169957480638670,\n",
       "  'image_id': 'a2f7ab86fb274aa0',\n",
       "  'iscrowd': 0,\n",
       "  'segmentation': []},\n",
       " {'IsDepiction': 1,\n",
       "  'IsInside': 0,\n",
       "  'IsOccluded': 0,\n",
       "  'IsTruncated': 0,\n",
       "  'area': 20,\n",
       "  'bbox': [443, 549, 5, 4],\n",
       "  'category_id': 14,\n",
       "  'id': 5930169957480638669,\n",
       "  'image_id': 'a2f7ab86fb274aa0',\n",
       "  'iscrowd': 0,\n",
       "  'segmentation': []},\n",
       " {'IsDepiction': 1,\n",
       "  'IsInside': 0,\n",
       "  'IsOccluded': 0,\n",
       "  'IsTruncated': 0,\n",
       "  'area': 0,\n",
       "  'bbox': [445, 588, 0, 5],\n",
       "  'category_id': 14,\n",
       "  'id': 5930169957480638668,\n",
       "  'image_id': 'a2f7ab86fb274aa0',\n",
       "  'iscrowd': 0,\n",
       "  'segmentation': []},\n",
       " {'IsDepiction': 1,\n",
       "  'IsInside': 0,\n",
       "  'IsOccluded': 0,\n",
       "  'IsTruncated': 0,\n",
       "  'area': 6,\n",
       "  'bbox': [445, 581, 3, 2],\n",
       "  'category_id': 14,\n",
       "  'id': 5930169957480638667,\n",
       "  'image_id': 'a2f7ab86fb274aa0',\n",
       "  'iscrowd': 0,\n",
       "  'segmentation': []},\n",
       " {'IsDepiction': 1,\n",
       "  'IsInside': 0,\n",
       "  'IsOccluded': 0,\n",
       "  'IsTruncated': 0,\n",
       "  'area': 10,\n",
       "  'bbox': [456, 473, 2, 5],\n",
       "  'category_id': 14,\n",
       "  'id': 5930169957480638666,\n",
       "  'image_id': 'a2f7ab86fb274aa0',\n",
       "  'iscrowd': 0,\n",
       "  'segmentation': []},\n",
       " {'IsDepiction': 1,\n",
       "  'IsInside': 0,\n",
       "  'IsOccluded': 0,\n",
       "  'IsTruncated': 0,\n",
       "  'area': 20,\n",
       "  'bbox': [456, 481, 5, 4],\n",
       "  'category_id': 14,\n",
       "  'id': 5930169957480638665,\n",
       "  'image_id': 'a2f7ab86fb274aa0',\n",
       "  'iscrowd': 0,\n",
       "  'segmentation': []},\n",
       " {'IsDepiction': 1,\n",
       "  'IsInside': 0,\n",
       "  'IsOccluded': 0,\n",
       "  'IsTruncated': 0,\n",
       "  'area': 30,\n",
       "  'bbox': [541, 464, 6, 5],\n",
       "  'category_id': 14,\n",
       "  'id': 5930169957480638664,\n",
       "  'image_id': 'a2f7ab86fb274aa0',\n",
       "  'iscrowd': 0,\n",
       "  'segmentation': []},\n",
       " {'IsDepiction': 1,\n",
       "  'IsInside': 0,\n",
       "  'IsOccluded': 0,\n",
       "  'IsTruncated': 0,\n",
       "  'area': 24,\n",
       "  'bbox': [544, 478, 4, 6],\n",
       "  'category_id': 14,\n",
       "  'id': 5930169957480638663,\n",
       "  'image_id': 'a2f7ab86fb274aa0',\n",
       "  'iscrowd': 0,\n",
       "  'segmentation': []},\n",
       " {'IsDepiction': 1,\n",
       "  'IsInside': 0,\n",
       "  'IsOccluded': 0,\n",
       "  'IsTruncated': 0,\n",
       "  'area': 20,\n",
       "  'bbox': [566, 377, 5, 4],\n",
       "  'category_id': 14,\n",
       "  'id': 5930169957480638662,\n",
       "  'image_id': 'a2f7ab86fb274aa0',\n",
       "  'iscrowd': 0,\n",
       "  'segmentation': []},\n",
       " {'IsDepiction': 1,\n",
       "  'IsInside': 0,\n",
       "  'IsOccluded': 0,\n",
       "  'IsTruncated': 0,\n",
       "  'area': 15,\n",
       "  'bbox': [567, 385, 3, 5],\n",
       "  'category_id': 14,\n",
       "  'id': 5930169957483638678,\n",
       "  'image_id': 'a2f7ab86fb274aa0',\n",
       "  'iscrowd': 0,\n",
       "  'segmentation': []},\n",
       " {'IsDepiction': 1,\n",
       "  'IsInside': 0,\n",
       "  'IsOccluded': 0,\n",
       "  'IsTruncated': 0,\n",
       "  'area': 30,\n",
       "  'bbox': [661, 384, 5, 6],\n",
       "  'category_id': 14,\n",
       "  'id': 5930169957483638679,\n",
       "  'image_id': 'a2f7ab86fb274aa0',\n",
       "  'iscrowd': 0,\n",
       "  'segmentation': []},\n",
       " {'IsDepiction': 1,\n",
       "  'IsInside': 0,\n",
       "  'IsOccluded': 0,\n",
       "  'IsTruncated': 0,\n",
       "  'area': 30,\n",
       "  'bbox': [665, 399, 5, 6],\n",
       "  'category_id': 14,\n",
       "  'id': 5930169957483638676,\n",
       "  'image_id': 'a2f7ab86fb274aa0',\n",
       "  'iscrowd': 0,\n",
       "  'segmentation': []},\n",
       " {'IsDepiction': 1,\n",
       "  'IsInside': 0,\n",
       "  'IsOccluded': 0,\n",
       "  'IsTruncated': 0,\n",
       "  'area': 413660,\n",
       "  'bbox': [129, 169, 559, 740],\n",
       "  'category_id': 147,\n",
       "  'id': 5930169957483638677,\n",
       "  'image_id': 'a2f7ab86fb274aa0',\n",
       "  'iscrowd': 0,\n",
       "  'segmentation': []},\n",
       " {'IsDepiction': 1,\n",
       "  'IsInside': 0,\n",
       "  'IsOccluded': 0,\n",
       "  'IsTruncated': 0,\n",
       "  'area': 534303,\n",
       "  'bbox': [73, 147, 693, 771],\n",
       "  'category_id': 176,\n",
       "  'id': 5930169957483638674,\n",
       "  'image_id': 'a2f7ab86fb274aa0',\n",
       "  'iscrowd': 0,\n",
       "  'segmentation': []},\n",
       " {'IsDepiction': 0,\n",
       "  'IsInside': 0,\n",
       "  'IsOccluded': 0,\n",
       "  'IsTruncated': 0,\n",
       "  'area': 198,\n",
       "  'bbox': [127, 253, 11, 18],\n",
       "  'category_id': 252,\n",
       "  'id': 5930169957483638675,\n",
       "  'image_id': 'a2f7ab86fb274aa0',\n",
       "  'iscrowd': 0,\n",
       "  'segmentation': []},\n",
       " {'IsDepiction': 0,\n",
       "  'IsInside': 0,\n",
       "  'IsOccluded': 0,\n",
       "  'IsTruncated': 0,\n",
       "  'area': 180,\n",
       "  'bbox': [136, 213, 10, 18],\n",
       "  'category_id': 252,\n",
       "  'id': 5930169957483638672,\n",
       "  'image_id': 'a2f7ab86fb274aa0',\n",
       "  'iscrowd': 0,\n",
       "  'segmentation': []},\n",
       " {'IsDepiction': 0,\n",
       "  'IsInside': 0,\n",
       "  'IsOccluded': 0,\n",
       "  'IsTruncated': 0,\n",
       "  'area': 63,\n",
       "  'bbox': [331, 635, 9, 7],\n",
       "  'category_id': 252,\n",
       "  'id': 5930169957483638673,\n",
       "  'image_id': 'a2f7ab86fb274aa0',\n",
       "  'iscrowd': 0,\n",
       "  'segmentation': []},\n",
       " {'IsDepiction': 0,\n",
       "  'IsInside': 0,\n",
       "  'IsOccluded': 0,\n",
       "  'IsTruncated': 0,\n",
       "  'area': 90,\n",
       "  'bbox': [354, 290, 10, 9],\n",
       "  'category_id': 252,\n",
       "  'id': 5930169957483638686,\n",
       "  'image_id': 'a2f7ab86fb274aa0',\n",
       "  'iscrowd': 0,\n",
       "  'segmentation': []},\n",
       " {'IsDepiction': 0,\n",
       "  'IsInside': 0,\n",
       "  'IsOccluded': 0,\n",
       "  'IsTruncated': 0,\n",
       "  'area': 84,\n",
       "  'bbox': [382, 552, 7, 12],\n",
       "  'category_id': 252,\n",
       "  'id': 5930169957483638687,\n",
       "  'image_id': 'a2f7ab86fb274aa0',\n",
       "  'iscrowd': 0,\n",
       "  'segmentation': []},\n",
       " {'IsDepiction': 0,\n",
       "  'IsInside': 0,\n",
       "  'IsOccluded': 0,\n",
       "  'IsTruncated': 0,\n",
       "  'area': 91,\n",
       "  'bbox': [405, 280, 7, 13],\n",
       "  'category_id': 252,\n",
       "  'id': 5930169957482638673,\n",
       "  'image_id': 'a2f7ab86fb274aa0',\n",
       "  'iscrowd': 0,\n",
       "  'segmentation': []},\n",
       " {'IsDepiction': 0,\n",
       "  'IsInside': 0,\n",
       "  'IsOccluded': 0,\n",
       "  'IsTruncated': 0,\n",
       "  'area': 52,\n",
       "  'bbox': [441, 650, 4, 13],\n",
       "  'category_id': 252,\n",
       "  'id': 5930169957482638672,\n",
       "  'image_id': 'a2f7ab86fb274aa0',\n",
       "  'iscrowd': 0,\n",
       "  'segmentation': []},\n",
       " {'IsDepiction': 0,\n",
       "  'IsInside': 0,\n",
       "  'IsOccluded': 0,\n",
       "  'IsTruncated': 0,\n",
       "  'area': 72,\n",
       "  'bbox': [441, 715, 6, 12],\n",
       "  'category_id': 252,\n",
       "  'id': 5930169957482638675,\n",
       "  'image_id': 'a2f7ab86fb274aa0',\n",
       "  'iscrowd': 0,\n",
       "  'segmentation': []},\n",
       " {'IsDepiction': 0,\n",
       "  'IsInside': 0,\n",
       "  'IsOccluded': 0,\n",
       "  'IsTruncated': 0,\n",
       "  'area': 99,\n",
       "  'bbox': [444, 680, 9, 11],\n",
       "  'category_id': 252,\n",
       "  'id': 5930169957482638674,\n",
       "  'image_id': 'a2f7ab86fb274aa0',\n",
       "  'iscrowd': 0,\n",
       "  'segmentation': []},\n",
       " {'IsDepiction': 0,\n",
       "  'IsInside': 0,\n",
       "  'IsOccluded': 0,\n",
       "  'IsTruncated': 0,\n",
       "  'area': 130,\n",
       "  'bbox': [499, 780, 13, 10],\n",
       "  'category_id': 252,\n",
       "  'id': 5930169957482638677,\n",
       "  'image_id': 'a2f7ab86fb274aa0',\n",
       "  'iscrowd': 0,\n",
       "  'segmentation': []},\n",
       " {'IsDepiction': 0,\n",
       "  'IsInside': 0,\n",
       "  'IsOccluded': 0,\n",
       "  'IsTruncated': 0,\n",
       "  'area': 132,\n",
       "  'bbox': [522, 596, 12, 11],\n",
       "  'category_id': 252,\n",
       "  'id': 5930169957482638676,\n",
       "  'image_id': 'a2f7ab86fb274aa0',\n",
       "  'iscrowd': 0,\n",
       "  'segmentation': []},\n",
       " {'IsDepiction': 0,\n",
       "  'IsInside': 0,\n",
       "  'IsOccluded': 0,\n",
       "  'IsTruncated': 0,\n",
       "  'area': 55,\n",
       "  'bbox': [570, 567, 5, 11],\n",
       "  'category_id': 252,\n",
       "  'id': 5930169957482638679,\n",
       "  'image_id': 'a2f7ab86fb274aa0',\n",
       "  'iscrowd': 0,\n",
       "  'segmentation': []},\n",
       " {'IsDepiction': 0,\n",
       "  'IsInside': 0,\n",
       "  'IsOccluded': 0,\n",
       "  'IsTruncated': 0,\n",
       "  'area': 66,\n",
       "  'bbox': [579, 726, 6, 11],\n",
       "  'category_id': 252,\n",
       "  'id': 5930169957482638678,\n",
       "  'image_id': 'a2f7ab86fb274aa0',\n",
       "  'iscrowd': 0,\n",
       "  'segmentation': []},\n",
       " {'IsDepiction': 0,\n",
       "  'IsInside': 0,\n",
       "  'IsOccluded': 0,\n",
       "  'IsTruncated': 0,\n",
       "  'area': 55,\n",
       "  'bbox': [584, 705, 5, 11],\n",
       "  'category_id': 252,\n",
       "  'id': 5930169957482638681,\n",
       "  'image_id': 'a2f7ab86fb274aa0',\n",
       "  'iscrowd': 0,\n",
       "  'segmentation': []},\n",
       " {'IsDepiction': 0,\n",
       "  'IsInside': 0,\n",
       "  'IsOccluded': 0,\n",
       "  'IsTruncated': 0,\n",
       "  'area': 63,\n",
       "  'bbox': [608, 267, 7, 9],\n",
       "  'category_id': 252,\n",
       "  'id': 5930169957482638680,\n",
       "  'image_id': 'a2f7ab86fb274aa0',\n",
       "  'iscrowd': 0,\n",
       "  'segmentation': []},\n",
       " {'IsDepiction': 0,\n",
       "  'IsInside': 0,\n",
       "  'IsOccluded': 0,\n",
       "  'IsTruncated': 0,\n",
       "  'area': 65,\n",
       "  'bbox': [616, 231, 5, 13],\n",
       "  'category_id': 252,\n",
       "  'id': 5930169957477638656,\n",
       "  'image_id': 'a2f7ab86fb274aa0',\n",
       "  'iscrowd': 0,\n",
       "  'segmentation': []},\n",
       " {'IsDepiction': 0,\n",
       "  'IsInside': 0,\n",
       "  'IsOccluded': 0,\n",
       "  'IsTruncated': 0,\n",
       "  'area': 144,\n",
       "  'bbox': [660, 836, 12, 12],\n",
       "  'category_id': 252,\n",
       "  'id': 5930169957477638657,\n",
       "  'image_id': 'a2f7ab86fb274aa0',\n",
       "  'iscrowd': 0,\n",
       "  'segmentation': []},\n",
       " {'IsDepiction': 1,\n",
       "  'IsInside': 0,\n",
       "  'IsOccluded': 0,\n",
       "  'IsTruncated': 0,\n",
       "  'area': 467347,\n",
       "  'bbox': [69, 165, 629, 743],\n",
       "  'category_id': 291,\n",
       "  'id': 5930169957477638658,\n",
       "  'image_id': 'a2f7ab86fb274aa0',\n",
       "  'iscrowd': 0,\n",
       "  'segmentation': []},\n",
       " {'IsDepiction': 1,\n",
       "  'IsInside': 0,\n",
       "  'IsOccluded': 0,\n",
       "  'IsTruncated': 0,\n",
       "  'area': 551232,\n",
       "  'bbox': [68, 134, 696, 792],\n",
       "  'category_id': 297,\n",
       "  'id': 5930169957477638659,\n",
       "  'image_id': 'a2f7ab86fb274aa0',\n",
       "  'iscrowd': 0,\n",
       "  'segmentation': []},\n",
       " {'IsDepiction': 1,\n",
       "  'IsInside': 0,\n",
       "  'IsOccluded': 0,\n",
       "  'IsTruncated': 0,\n",
       "  'area': 84972,\n",
       "  'bbox': [10, 592, 291, 292],\n",
       "  'category_id': 365,\n",
       "  'id': 5930169957477638660,\n",
       "  'image_id': 'a2f7ab86fb274aa0',\n",
       "  'iscrowd': 0,\n",
       "  'segmentation': []},\n",
       " {'IsDepiction': 0,\n",
       "  'IsInside': 0,\n",
       "  'IsOccluded': 0,\n",
       "  'IsTruncated': 0,\n",
       "  'area': 63104,\n",
       "  'bbox': [25, 374, 272, 232],\n",
       "  'category_id': 365,\n",
       "  'id': 5930169957477638661,\n",
       "  'image_id': 'a2f7ab86fb274aa0',\n",
       "  'iscrowd': 0,\n",
       "  'segmentation': []},\n",
       " {'IsDepiction': 0,\n",
       "  'IsInside': 0,\n",
       "  'IsOccluded': 0,\n",
       "  'IsTruncated': 0,\n",
       "  'area': 71383,\n",
       "  'bbox': [31, 92, 247, 289],\n",
       "  'category_id': 365,\n",
       "  'id': 5930169957477638662,\n",
       "  'image_id': 'a2f7ab86fb274aa0',\n",
       "  'iscrowd': 0,\n",
       "  'segmentation': []},\n",
       " {'IsDepiction': 0,\n",
       "  'IsInside': 0,\n",
       "  'IsOccluded': 0,\n",
       "  'IsTruncated': 1,\n",
       "  'area': 533708,\n",
       "  'bbox': [81, 147, 686, 778],\n",
       "  'category_id': 432,\n",
       "  'id': 5930169957477638663,\n",
       "  'image_id': 'a2f7ab86fb274aa0',\n",
       "  'iscrowd': 0,\n",
       "  'segmentation': []},\n",
       " {'IsDepiction': 0,\n",
       "  'IsInside': 0,\n",
       "  'IsOccluded': 0,\n",
       "  'IsTruncated': 0,\n",
       "  'area': 453492,\n",
       "  'bbox': [78, 165, 612, 741],\n",
       "  'category_id': 501,\n",
       "  'id': 5930169957477638664,\n",
       "  'image_id': 'a2f7ab86fb274aa0',\n",
       "  'iscrowd': 0,\n",
       "  'segmentation': []},\n",
       " {'IsDepiction': 0,\n",
       "  'IsInside': 0,\n",
       "  'IsOccluded': 0,\n",
       "  'IsTruncated': 0,\n",
       "  'area': 440,\n",
       "  'bbox': [129, 477, 20, 22],\n",
       "  'category_id': 567,\n",
       "  'id': 5930169957477638665,\n",
       "  'image_id': 'a2f7ab86fb274aa0',\n",
       "  'iscrowd': 0,\n",
       "  'segmentation': []},\n",
       " {'IsDepiction': 0,\n",
       "  'IsInside': 0,\n",
       "  'IsOccluded': 0,\n",
       "  'IsTruncated': 0,\n",
       "  'area': 462,\n",
       "  'bbox': [137, 717, 21, 22],\n",
       "  'category_id': 567,\n",
       "  'id': 5930169957476638659,\n",
       "  'image_id': 'a2f7ab86fb274aa0',\n",
       "  'iscrowd': 0,\n",
       "  'segmentation': []},\n",
       " {'IsDepiction': 0,\n",
       "  'IsInside': 0,\n",
       "  'IsOccluded': 0,\n",
       "  'IsTruncated': 0,\n",
       "  'area': 42,\n",
       "  'bbox': [384, 410, 6, 7],\n",
       "  'category_id': 567,\n",
       "  'id': 5930169957476638658,\n",
       "  'image_id': 'a2f7ab86fb274aa0',\n",
       "  'iscrowd': 0,\n",
       "  'segmentation': []},\n",
       " {'IsDepiction': 0,\n",
       "  'IsInside': 0,\n",
       "  'IsOccluded': 0,\n",
       "  'IsTruncated': 0,\n",
       "  'area': 36,\n",
       "  'bbox': [547, 474, 6, 6],\n",
       "  'category_id': 567,\n",
       "  'id': 5930169957476638657,\n",
       "  'image_id': 'a2f7ab86fb274aa0',\n",
       "  'iscrowd': 0,\n",
       "  'segmentation': []},\n",
       " {'IsDepiction': 0,\n",
       "  'IsInside': 0,\n",
       "  'IsOccluded': 0,\n",
       "  'IsTruncated': 0,\n",
       "  'area': 108,\n",
       "  'bbox': [666, 391, 9, 12],\n",
       "  'category_id': 567,\n",
       "  'id': 5930169957476638656,\n",
       "  'image_id': 'a2f7ab86fb274aa0',\n",
       "  'iscrowd': 0,\n",
       "  'segmentation': []}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coco_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "output_folder = Path(\".\").resolve().parent / \"input\" / \"as_mscoco\" / \"annotations\" \n",
    "annotations_file = output_folder / \"train_overfit.json\"\n",
    "\n",
    "with open(annotations_file.as_posix(), 'r') as h:\n",
    "    annotations = json.load(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in annotations['annotations']:\n",
    "    bbox = a['bbox']\n",
    "    img_info = [im for im in annotations['images'] if im['id'] == a['image_id']]\n",
    "    assert len(img_info) == 1\n",
    "    img_info = img_info[0]\n",
    "    w = img_info['width']\n",
    "    h = img_info['height']\n",
    "    assert 0 <= bbox[0] <= w, \"Problem with {}, {}\".format(a, img_info)\n",
    "    assert 0 <= bbox[1] <= h, \"Problem with {}, {}\".format(a, img_info)\n",
    "    assert 0 <= bbox[0] + bbox[2] <= w, \"Problem with {}, {}\".format(a, img_info)\n",
    "    assert 0 <= bbox[1] + bbox[3] <= h, \"Problem with {}, {}\".format(a, img_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
