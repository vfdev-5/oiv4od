{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run validation scripts in cmd\n",
    "and keep history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:98% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:98% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd=!cd ../ && echo ${PWD}/\n",
    "pwd = Path(pwd[0])\n",
    "data_dir = (pwd / \"input\" / \"as_mscoco\")\n",
    "\n",
    "os.environ['DATA_DIR'] = data_dir.as_posix()\n",
    "os.environ['CUSTOM_DATASETS'] = (pwd / \"datasets\" / \"dataset_catalog.py\").as_posix()\n",
    "base_output_path = Path(\"/home/storage_ntfs_1tb\")\n",
    "assert base_output_path.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Detectron = (Path(\".\").absolute().parent / \"Detectron.pytorch\").as_posix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gt_bboxes_labels(image_id, annotations):\n",
    "    selected_annotations = [a for a in gt_annotations if a['image_id'] == image_id]\n",
    "    if len(selected_annotations) == 0:\n",
    "        return []\n",
    "    \n",
    "    bboxes_labels = [(a['bbox'], str(a['category_id'])) for a in selected_annotations]\n",
    "    return bboxes_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade image-dataset-viz\n",
    "from image_dataset_viz import render_datapoint, bbox_to_points, xywh_to_xyxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_gt_target(img_path, image_id, annotations):\n",
    "    img = Image.open(img_path / \"{}.jpg\".format(image_id))\n",
    "    targets = [(bbox_to_points(xywh_to_xyxy(b)), l) for b, l in get_gt_bboxes_labels(image_id, gt_annotations)]\n",
    "    return render_datapoint(img, targets, output_size=(430, 430))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate models\n",
    "\n",
    "Validation dataset contains: 41620 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41620\n"
     ]
    }
   ],
   "source": [
    "!find ${DATA_DIR}/val/ -name *.jpg | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
      "/usr/local/lib/python3.5/dist-packages/torch/nn/functional.py:1006: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/working_directory/ml/kaggle/OpenImagesObjectDetection/Detectron.pytorch/tools/test_net.py\", line 100, in <module>\n",
      "    check_expected_results=True)\n",
      "  File \"/home/working_directory/ml/kaggle/OpenImagesObjectDetection/Detectron.pytorch/lib/core/test_engine.py\", line 128, in run_inference\n",
      "    all_results = result_getter()\n",
      "  File \"/home/working_directory/ml/kaggle/OpenImagesObjectDetection/Detectron.pytorch/lib/core/test_engine.py\", line 108, in result_getter\n",
      "    multi_gpu=multi_gpu_testing\n",
      "  File \"/home/working_directory/ml/kaggle/OpenImagesObjectDetection/Detectron.pytorch/lib/core/test_engine.py\", line 163, in test_net_on_dataset\n",
      "    dataset, all_boxes, all_segms, all_keyps, output_dir\n",
      "  File \"/home/working_directory/ml/kaggle/OpenImagesObjectDetection/Detectron.pytorch/lib/datasets/task_evaluation.py\", line 59, in evaluate_all\n",
      "    dataset, all_boxes, output_dir, use_matlab=use_matlab\n",
      "  File \"/home/working_directory/ml/kaggle/OpenImagesObjectDetection/Detectron.pytorch/lib/datasets/task_evaluation.py\", line 97, in evaluate_boxes\n",
      "    'No evaluator for dataset: {}'.format(dataset.name)\n",
      "NotImplementedError: No evaluator for dataset: open_images_v4_val\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "\n",
    "config_name = \"finetune_faster_rcnn_X-101-64x4d-FPN_2x_gpu_1\"\n",
    "common_output_path = base_output_path / \"output-OpenImagesObjectDetections\" / config_name / \"20180805_1459\"\n",
    "output_path = common_output_path / \"val\" / now.strftime(\"%Y%m%d_%H%M\")\n",
    "ckpt_weights_path = common_output_path / \"ckpt\" / \"model_step24999.pth\"\n",
    "config = Path(\".\") / \"configs\" / \"train\" / \"{}.yaml\".format(config_name)\n",
    "other_confs = \"NUM_GPUS 1 \"\n",
    "\n",
    "!mkdir -p {output_path}\n",
    "output_path = output_path.as_posix()\n",
    "cmd = \"{Detectron}/tools/test_net.py --cfg {config} --set {other_confs}\".format(Detectron=Detectron, config=config, other_confs=other_confs) + \\\n",
    "    \"--output_dir {output_path} --load_ckpt {ckpt_weights_path} \".format(output_path=output_path, ckpt_weights_path=ckpt_weights_path)\n",
    "\n",
    "!echo python3 {cmd} > {output_path}/run.cmd\n",
    "!python3 {cmd} > {output_path}/val.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "detections_pkl = Path(output_path) / \"detections.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, (Path(\".\").resolve().parent / \"Detectron.pytorch\" / \"lib\").as_posix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.config import cfg, cfg_from_file, assert_and_infer_cfg\n",
    "\n",
    "cfg_from_file(config.as_posix())\n",
    "assert_and_infer_cfg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import task_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "with detections_pkl.open('rb') as fp:\n",
    "    detections = pickle.load(fp, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.75s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "from datasets.json_dataset import JsonDataset\n",
    "\n",
    "dataset = JsonDataset('open_images_v4_val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=7.87s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=341.40s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=62.92s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.020\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.035\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.020\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.010\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.023\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.039\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.058\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.059\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.022\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.052\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/core/fromnumeric.py:2957: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "results = task_evaluation.evaluate_all(\n",
    "    dataset, detections['all_boxes'], detections['all_segms'], detections['all_keyps'], output_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test models\n",
    "\n",
    "Test dataset contains: 125436 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125436\n"
     ]
    }
   ],
   "source": [
    "!find ${DATA_DIR}/test/ -name *.jpg | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/torch/nn/functional.py:1890: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
      "/usr/local/lib/python3.5/dist-packages/torch/nn/functional.py:1006: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/working_directory/ml/kaggle/OpenImagesObjectDetection/Detectron.pytorch/tools/test_net.py\", line 100, in <module>\n",
      "    check_expected_results=True)\n",
      "  File \"/home/working_directory/ml/kaggle/OpenImagesObjectDetection/Detectron.pytorch/lib/core/test_engine.py\", line 128, in run_inference\n",
      "    all_results = result_getter()\n",
      "  File \"/home/working_directory/ml/kaggle/OpenImagesObjectDetection/Detectron.pytorch/lib/core/test_engine.py\", line 108, in result_getter\n",
      "    multi_gpu=multi_gpu_testing\n",
      "  File \"/home/working_directory/ml/kaggle/OpenImagesObjectDetection/Detectron.pytorch/lib/core/test_engine.py\", line 163, in test_net_on_dataset\n",
      "    dataset, all_boxes, all_segms, all_keyps, output_dir\n",
      "  File \"/home/working_directory/ml/kaggle/OpenImagesObjectDetection/Detectron.pytorch/lib/datasets/task_evaluation.py\", line 59, in evaluate_all\n",
      "    dataset, all_boxes, output_dir, use_matlab=use_matlab\n",
      "  File \"/home/working_directory/ml/kaggle/OpenImagesObjectDetection/Detectron.pytorch/lib/datasets/task_evaluation.py\", line 97, in evaluate_boxes\n",
      "    'No evaluator for dataset: {}'.format(dataset.name)\n",
      "NotImplementedError: No evaluator for dataset: open_images_v4_val\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "\n",
    "config_name = \"finetune_faster_rcnn_X-101-64x4d-FPN_2x_gpu_1\"\n",
    "common_output_path = base_output_path / \"output-OpenImagesObjectDetections\" / config_name / \"20180805_1459\"\n",
    "output_path = common_output_path / \"val\" / now.strftime(\"%Y%m%d_%H%M\")\n",
    "ckpt_weights_path = common_output_path / \"ckpt\" / \"model_step24999.pth\"\n",
    "config = Path(\".\") / \"configs\" / \"train\" / \"{}.yaml\".format(config_name)\n",
    "other_confs = \"NUM_GPUS 1 \"\n",
    "\n",
    "\n",
    "!mkdir -p {output_path}\n",
    "output_path = output_path.as_posix()\n",
    "cmd = \"{Detectron}/tools/test_net.py --cfg {config} --set {other_confs}\".format(Detectron=Detectron, config=config, other_confs=other_confs) + \\\n",
    "    \"--output_dir {output_path} --load_ckpt {ckpt_weights_path} \".format(output_path=output_path, ckpt_weights_path=ckpt_weights_path)\n",
    "\n",
    "!echo python3 {cmd} > {output_path}/run.cmd\n",
    "!python3 {cmd} > {output_path}/test.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
